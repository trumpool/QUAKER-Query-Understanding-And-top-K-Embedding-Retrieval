{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJbbSBtakOI8",
        "outputId": "1016abaa-c8da-463a-a8d8-6904760e015a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.1.0 Requires-Python <3.13,>=3.8.1; 0.1.0rc1 Requires-Python <3.13,>=3.8.1; 0.1.1 Requires-Python <3.13,>=3.8.1; 0.1.2 Requires-Python <4,>=3.8.1; 0.1.3 Requires-Python <4,>=3.8.1; 0.1.4 Requires-Python <4,>=3.8.1; 0.2.0 Requires-Python <4,>=3.9; 0.2.1 Requires-Python <4,>=3.9; 0.2.2 Requires-Python <4,>=3.9; 0.2.3 Requires-Python <4,>=3.9; 0.2.4 Requires-Python >=3.9; 0.2.5 Requires-Python >=3.9; 0.2.6 Requires-Python >=3.9; 1.0.0 Requires-Python <4.0.0,>=3.10.0; 1.0.0a1 Requires-Python <4.0.0,>=3.10.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement langchain_chroma (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/data/xiangjun/conda3/envs/env/bin/python -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for langchain_chroma\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -q torch transformers langchain_chroma bitsandbytes langchain faiss-gpu langchain_huggingface langchain-community sentence-transformers  pacmap tqdm matplotlib datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "coQaOx1ekRVI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/data/xiangjun/conda3/envs/env/bin/python -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -q sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBPrmldbkT-b",
        "outputId": "820a31e7-a0dc-4361-f013-6e9cf31ce271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.8.3\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Npjn57tfkXT_"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "from typing import Optional, List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "import torch\n",
        "\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob1UrtlfkeI0"
      },
      "source": [
        "## Processing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "9b58a7a438f540858f14cc4ea9b7fb1d",
            "2d597758d3a54bb2aa4148e77bc92eac",
            "2f2c4f88d629433a8944872fb4436fd8",
            "c010a2decfba49fc912c20ed792a9d98",
            "a9b1cf3d3e474f5bbd365eff024e1056",
            "f966d2ff93cb4762bfbe0a2682415c54",
            "acad02eb3ffe48948280b97ed8bf7af0",
            "31eaea5fd6d44ad1b7c015a81279636a",
            "b98c60e47b3a489194b30fa0daca1395",
            "54894e2917404213a5572b4cff082c55",
            "d8ac9b6e2c2848a98baeefee0eff0184"
          ]
        },
        "id": "gle1wcMAkcOo",
        "outputId": "59307690-4bb0-4fe5-e265-88e58a9f5ca5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "filepath = hf_hub_download(\n",
        "    repo_id='McAuley-Lab/Amazon-C4',\n",
        "    filename='sampled_item_metadata_1M.jsonl',\n",
        "    repo_type='dataset'\n",
        ")\n",
        "\n",
        "item_pool = []\n",
        "with open(filepath, 'r') as file:\n",
        "    for line in file:\n",
        "        item_pool.append(json.loads(line.strip()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125,
          "referenced_widgets": [
            "207af96f17144dabbd4cfcbfae76811c",
            "1bfade78ab6d42e7b479a8b6be6a39d4",
            "cbf1535325684729955336fe5ee3ed69",
            "8d84a237916c497d967412abbe0d902c",
            "3909fdc11af244bea3764523f70f5214",
            "b418e129237c4906baadb6864ecc8557",
            "e3a55a3b85834b99bb0062d638fb1bc8",
            "64998507785348078f33c5389ffa403b",
            "44023ba1225040789c4f16504de793eb",
            "c954b5fa573c4e80bc281b8c54248195",
            "ef8b23e3d7564c00ad125c0d6b757cef",
            "644e1cf337064e87ab83384ae2fa0a30",
            "16b2735c8bec4d36b27cb4f7cd3515bd",
            "923d4766a9604a698ed5f42cb35cdc55",
            "ee0e7ce246274f4daf7d485613a68270",
            "98ef8156b7944e16bbd42f8169317a14",
            "12314ba247a448839fa9ce38b2f220ef",
            "2122f0efd71d4e78b55b2fe3dae9b096",
            "f277733f38fa4fee855291c03d58dc17",
            "2db9e925f5314dafbab193290f8dbd33",
            "845bb87e292b41bb9d8e08f58e99b391",
            "b3469c0ef38946afa1e383ef01db0ed9",
            "970e81071f844970a4beb77e2f95313d",
            "3224a18f2377499a8222b710460c6d93",
            "8badfe92a3ac4fb7ab8290d7c466d9e1",
            "7ecd523584b54ac0987bd2c21015eff1",
            "82b56d14bc9c43de9e36a99be3283876",
            "58bd9f9feca544e7bafe75a3920f6486",
            "0ed1af681d0945ab8278ece78a7cf64d",
            "c4237f0dc7ea463bb6da263837d3351b",
            "8a5c789d6bbb4b3fa9b6cd9ea0603e1e",
            "cd100f2a9a314cc5a009818881e477d5",
            "1dab1afb710c434281b482b65aa2f403"
          ]
        },
        "id": "ox2xAYEbkq-7",
        "outputId": "209e2fb9-4908-41a3-e02c-da3ff0afbeb6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('McAuley-Lab/Amazon-C4')['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "P4pcJtuFktH2"
      },
      "outputs": [],
      "source": [
        "item_metadata_map = {item['item_id']: {'metadata': item['metadata'], 'category': item['category']} for item in item_pool}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t4XCczKtktc3"
      },
      "outputs": [],
      "source": [
        "# new_list = []\n",
        "# for data in dataset:\n",
        "#     item_id = data['item_id']\n",
        "#     item_info = item_metadata_map.get(item_id, {'metadata': None, 'category': None})  # 找到 metadata 和 category\n",
        "#     new_entry = {\n",
        "#         'query': data['query'],\n",
        "#         'item_id': item_id,\n",
        "#         'metadata': item_info['metadata'],\n",
        "#         'category': item_info['category']\n",
        "#     }\n",
        "#     new_list.append(new_entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jkfTSOukNMKZ"
      },
      "outputs": [],
      "source": [
        "new_list = []\n",
        "for data in dataset:\n",
        "    item_id = data['item_id']\n",
        "    item_info = item_metadata_map.get(item_id, {'metadata': None, 'category': None})\n",
        "\n",
        "    metadata = item_info['metadata']\n",
        "    if metadata is None or len(metadata.split()) < 10:\n",
        "        continue\n",
        "\n",
        "    new_entry = {\n",
        "        'query': data['query'],\n",
        "        'item_id': item_id,\n",
        "        'metadata': metadata,\n",
        "        'category': item_info['category']\n",
        "    }\n",
        "    new_list.append(new_entry)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G4Hbz0ZNNmh",
        "outputId": "2ebd8a17-648f-49a3-b82e-f5979efd21dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20250\n"
          ]
        }
      ],
      "source": [
        "print(len(new_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RmeYeA80kwCW"
      },
      "outputs": [],
      "source": [
        "queries = []\n",
        "passages = []\n",
        "\n",
        "\n",
        "limit = max(1, len(new_list) // 20)\n",
        "\n",
        "for idx, entry in enumerate(new_list):\n",
        "    if idx < limit:\n",
        "        queries.append(f\"query: {entry['query']}\")\n",
        "        passages.append(f\"passage: {entry['metadata']}\")\n",
        "\n",
        "input_texts = queries + passages\n",
        "\n",
        "# print(input_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4YxpbNlmu1z",
        "outputId": "0c17eb38-4c4f-45f7-e2d9-c58c57faf26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 18225\n",
            "Test samples: 2025\n",
            "Number of categories: 30\n"
          ]
        }
      ],
      "source": [
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "random.shuffle(new_list)\n",
        "split_idx = int(0.9 * len(new_list))\n",
        "train_pool = new_list[:split_idx]\n",
        "test_pool = new_list[split_idx:]\n",
        "\n",
        "def prepare_dataset(pool):\n",
        "    # 修改：使用 query 而不是 metadata 来训练分类器\n",
        "    queries = [item['query'] for item in pool if item['query'] and item['category']]\n",
        "    categories = [item['category'] for item in pool if item['query'] and item['category']]\n",
        "    return queries, categories\n",
        "\n",
        "train_queries, train_categories = prepare_dataset(train_pool)\n",
        "test_queries, test_categories = prepare_dataset(test_pool)\n",
        "\n",
        "category_to_idx = {category: idx for idx, category in enumerate(set(train_categories))}\n",
        "idx_to_category = {idx: category for category, idx in category_to_idx.items()}\n",
        "train_labels = [category_to_idx[cat] for cat in train_categories]\n",
        "test_labels = [category_to_idx[cat] for cat in test_categories]\n",
        "\n",
        "print(f\"Training samples: {len(train_queries)}\")\n",
        "print(f\"Test samples: {len(test_queries)}\")\n",
        "print(f\"Number of categories: {len(category_to_idx)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "3a04bde07d404f719d374e145dfb1d29",
            "b730f8d8d0854178a65aa0073a555ced",
            "30102fcd31f949dfb036e43946d34362",
            "9e1c0d462f1e4cf99ad646298bb842f0",
            "68e32e0876ac40f99a149a423d3138fc",
            "d2827be78bb14160b4ab27a09be516d1",
            "fd4ca22adba849ed8af9a497da43c524",
            "0e9d7743ee044b1291f8a666885665b7",
            "32424e3258374cfa9cc5192716631a24",
            "371f574d0a7a4ee3a2cbe9fc185e7b85",
            "0a9ae83ec29b4aba94d69295a58ab7ca",
            "245d6ac60c4940bbbdd7da49d7c24392",
            "8207d2bc739e4bd7ba33ce18084be8c7",
            "1676beb882b54014b9efcb78acbf0064",
            "0454c7c4c7d04d8292d3eb923145735f",
            "83af95e9a4b1499c92a3bd11c3fb488b",
            "c422ab5f4bf34cdd97fd6d12141202c9",
            "d4ddb6c357d241718a4e2782a22742c4",
            "1b8d0060d4fd4fb5aaf73a230a819b63",
            "6092842d22094ab6a5d8ea925499e975",
            "9d41c00357ca46a08ad503726da364c4",
            "e42e616d3ec4482f9f18bf1e50708b07",
            "67bb091e4d22493d846b19df6b9e1007",
            "37730ac017dc48c5a8654b4a4ad8ab36",
            "e07942374f5842fb8bcdab97f9cee436",
            "f3bf489031f74dc793d0c499adde5e7d",
            "07ed5b9c95e94170b036b4b68828f67a",
            "e228d66c30d74d098df13c9c4ef06b68",
            "765a7d6d477a4a82904dc24e0930c306",
            "66d26555f6cf49c6ac88bbc4430e88ca",
            "56076a15eb8741218bbe5ed7b7e1de16",
            "e8f6b9bd11154c159c02fb85c7561070",
            "2d995e9602d54fe2a02d7163b2d8a1d3",
            "c5612fea30f442b1b7545e0718e3285e",
            "d0f60f8204fd4f5cad6d01578f532459",
            "3847801e914e42a49f24514c3235deee",
            "1bfe52c58b744706b2d7491141984a3f",
            "881ac395034a4bbc8fba3e2f942139d4",
            "8048612f80454d6e82c1c19c51aab67e",
            "7c35819630354a27aea0eb3f61692518",
            "2cbd0c1cd74a40df918d59279423e070",
            "70e568bca3864ab0bc1ab87b0d485ed2",
            "72f5b492359945cc9c2bb55c6db8c36d",
            "9198722879ff4f3c902d7e74c9e7dfe9"
          ]
        },
        "id": "cnLzIPqOmxuR",
        "outputId": "79df6917-f2e9-40b7-cd57-1f2b60bdf062"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09637549c1f240388d47823a7cbc7f6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5169121d8ea4f0eb0ae010bce41ce5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0a63b7e54334706bc3c9a74b96427c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class QueryDataset(Dataset):\n",
        "    def __init__(self, queries, labels, tokenizer, max_len=128):\n",
        "        self.queries = queries\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.queries)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        query = self.queries[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            query,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
        "\n",
        "train_dataset = QueryDataset(train_queries, train_labels, tokenizer)\n",
        "test_dataset = QueryDataset(test_queries, test_labels, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jV9HBwZmzxK",
        "outputId": "98a3a578-ddbe-48a1-8351-0b647bcdf928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6ca2c1d65a8e49e49b4348f3e4c79e91",
            "ff432ede29954e309c2409da3f3ff704",
            "0618413f88c84adfbf4318e4afcc383b",
            "cf78e24beda34a658309ef5cc3c4df85",
            "0c8f35383b044479a12ee0df2ee675fc",
            "5879914352de48f6b3aec60a9bed8a32",
            "ee2ce76ec7f64dffb5a101d9994405f2",
            "c1db8b9ae8564d07a8a86bdb2a32fe3d",
            "adcca592f6c1447eb52478b00da56dda",
            "5efd248fb53842298dee52c59cda8290",
            "fbd25ebad5b94a9e811cc9a7a6c3c575"
          ]
        },
        "id": "Bk3latAPn6HW",
        "outputId": "dab471fe-ea05-478c-c3fd-9b556b31e596"
      },
      "outputs": [],
      "source": [
        "class QueryClassifier(nn.Module):\n",
        "    def __init__(self, num_categories):\n",
        "        super(QueryClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-large-uncased\")\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.bert.config.hidden_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_categories)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_token = outputs.last_hidden_state[:, 0, :]  # [CLS] token embedding\n",
        "        logits = self.classifier(cls_token)\n",
        "        return logits\n",
        "\n",
        "num_categories = len(category_to_idx)\n",
        "model = QueryClassifier(num_categories).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYBpE8ann8Hg",
        "outputId": "098263d0-7370-47d5-c4c7-9aae9795347e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 1: 100%|███████████████████████████████████████████████████████████████| 570/570 [05:17<00:00,  1.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.7839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 2: 100%|███████████████████████████████████████████████████████████████| 570/570 [05:17<00:00,  1.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 1.0927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 3: 100%|███████████████████████████████████████████████████████████████| 570/570 [05:19<00:00,  1.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 0.8381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Epoch 4: 100%|███████████████████████████████████████████████████████████████| 570/570 [05:19<00:00,  1.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 0.6414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, train_loader, test_loader, num_epochs=3, lr=1e-5):\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "model = train_model(model, train_loader, test_loader, num_epochs=4)\n",
        "classifier_model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3Y3AvWEoE2z",
        "outputId": "349059c9-aac0-4612-c4fb-b30be7408853"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|███████████████████████████████████████████████████████████████████████| 64/64 [00:13<00:00,  4.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-4 Accuracy: 0.8909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, test_loader, top_k=3):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            _, top_preds = torch.topk(outputs, k=top_k, dim=-1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(top_preds.cpu().numpy())\n",
        "\n",
        "    top_k_accuracy = 0\n",
        "    for label, preds in zip(all_labels, all_predictions):\n",
        "        if label in preds:\n",
        "            top_k_accuracy += 1\n",
        "\n",
        "    top_k_accuracy /= len(all_labels)\n",
        "    print(f\"Top-{top_k} Accuracy: {top_k_accuracy:.4f}\")\n",
        "\n",
        "evaluate_model(classifier_model, test_loader, top_k=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D73MWnyooIvX",
        "outputId": "ce2d3d89-3f60-406e-8e29-433d496331fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference: Using trained query classifier to predict categories...\n",
            "✓ Processed 2025 test queries\n",
            "  Average candidate pool size: 4958\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.functional import softmax\n",
        "\n",
        "result_list = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(\"Running inference: Using trained query classifier to predict categories...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(test_loader):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "        # 现在 test_loader 中是真实的 query，直接用来预测类别\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        probabilities = softmax(logits, dim=-1)\n",
        "\n",
        "        # 获取 top-2 预测类别 (categories # changed to 4)\n",
        "        top2_indices = torch.topk(probabilities, 4, dim=-1).indices.cpu().numpy()\n",
        "\n",
        "        for i, top2 in enumerate(top2_indices):\n",
        "            top2_categories = [idx_to_category[idx] for idx in top2]\n",
        "\n",
        "            # 根据预测的类别筛选候选商品\n",
        "            matched_items = [\n",
        "                {\n",
        "                    \"item_id\": item[\"item_id\"],\n",
        "                    \"metadata\": item[\"metadata\"],\n",
        "                    \"category\": item[\"category\"],\n",
        "                }\n",
        "                for item in new_list\n",
        "                if item[\"category\"] in top2_categories\n",
        "            ]\n",
        "\n",
        "            # 获取对应的真实 query 和 ground truth\n",
        "            test_idx = batch_idx * test_loader.batch_size + i\n",
        "            result_list.append({\n",
        "                \"query\": test_pool[test_idx]['query'],\n",
        "                \"real_category\": test_pool[test_idx]['category'],\n",
        "                \"real_item_id\": test_pool[test_idx]['item_id'],\n",
        "                \"top2_categories\": top2_categories,\n",
        "                \"matched_items\": matched_items\n",
        "            })\n",
        "\n",
        "print(f\"✓ Processed {len(result_list)} test queries\")\n",
        "print(f\"  Average candidate pool size: {sum(len(r['matched_items']) for r in result_list) / len(result_list):.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYBjhyLdoKb2",
        "outputId": "557b75f9-f78d-4377-8845-356e15dc1cd3"
      },
      "source": [
        "## ✅ 改进说明：Query-Based 分类器\n",
        "\n",
        "**主要修改**:\n",
        "- **Cell 12**: `prepare_dataset()` 现在使用 `item['query']` 而不是 `item['metadata']`\n",
        "- **Cell 18**: 推理时直接用 query 预测类别，无需额外添加\n",
        "\n",
        "**新的训练流程**:\n",
        "```\n",
        "用户 query → BERT QueryClassifier → Top-2 categories → 候选商品池\n",
        "```\n",
        "\n",
        "**优势**:\n",
        "1. ✅ Query 真正参与训练\n",
        "2. ✅ 推理流程符合实际应用 (用户只提供 query)\n",
        "3. ✅ 代码更简洁，逻辑更清晰\n",
        "\n",
        "**下一步**: 重新运行 Cell 12-18 来训练新的 query 分类器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFiRSBrx0RZ1",
        "outputId": "9d5fc508-1547-4b5d-a515-8bb7fa76f6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved query_classifier.pth\n",
            "  Model has 30 output categories\n"
          ]
        }
      ],
      "source": [
        "# Save the trained QueryClassifier model\n",
        "torch.save(model.state_dict(), 'query_classifier.pth')\n",
        "classifier_model = model  # Keep a reference before it gets overwritten\n",
        "print(\"✓ Saved query_classifier.pth\")\n",
        "print(f\"  Model has {num_categories} output categories\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "7da698f4e9a841b18b62fa8aca34ba8d",
            "63a15e070eab45f482d2f179492f9247",
            "a67085c7ce5e416da38670b3e87b3c3e",
            "829ed8b343fd44bba6d70a40f5aa348c",
            "5d67244ddead40dc8f0047a3380b0840",
            "e9e5524530b64cc19c8edf589d19e739",
            "557a32a7a57b40649f6c5287e23d4cd3",
            "ee25065705994755adeab8129d9c87b4",
            "c870762e361f4b43b3349778aca74289",
            "e26e8df1c2d1498abd39c51c41875a15",
            "321cd1d328944060a3231c05b23ccd37",
            "4359ca1454b14d5ba1a26cbb7561d724",
            "fad6a11caf3f43f2b6deaa4c1c7dad46",
            "6d6dffcda9754aef9bc31ab111a2169f",
            "cc546f4dd9e1407ab3d03bfdc14bfa09",
            "b2a07b3a72fe4b928c9534ff5fc1e411",
            "adc1add5a65a4aebae8e8c3c2bf1b0f4",
            "dabd53032f8447f9b38903ed92f0006f",
            "5dbe2841789b456db9a4b0b984080620",
            "8ff1ea5f6e03486e842c84fbf63ed8c2",
            "7a5db845d00e42ab87512522f3ae7fae",
            "d49aa549aa814b3eb407bf03ba1a573a",
            "817ddf0066914364a28f963f490b81e7",
            "22a0d265a1c14b98b5abd96d127066b1",
            "2ba4e1e40c3e4af3ade017b1b402ef6e",
            "b45895fa892d4fb78c2552d2de73615e",
            "df055e91d8d44e78aaec77ae6d27439f",
            "ca0d6cfdf3544194839e85e452769b5e",
            "e57f927956444c8bbdccbb3102310ebf",
            "7be2ad532b4d4d009ea8fbd907fb71c9",
            "c5edd640a05c4641b09f67e6a60d7988",
            "5ef156d3ad5c415986c5af09ae5580c1",
            "147c8682f97e4fff8ebd52b07dbbac59",
            "27e50e66734743d888de390a87b9cdc7",
            "4bc82567301d45a9b12d3810e670f322",
            "867734377f20490d8973b22bd3609a21",
            "e76fafb60971490192188c888c830a5c",
            "fb6377c61fcd46efaaf622df834489cb",
            "a7ab6773cf71495ca54f959d67fe8ec9",
            "98229ce7b09e45f78d416db3154454d8",
            "dbe657e0f2aa41d8b4363ed8f08ae2b4",
            "305eadd842fa431882a8e203b75a6796",
            "767b0e5adf1d48c789386fdfaa579081",
            "7f5941a26adf4194918f5e179b91ef98",
            "4739bf13739c4940ac0811533cc881e0",
            "6383974f9b47437e867a55e8fb4000bc",
            "23bd601cfb524ad8beaadde754bf2a73",
            "5264d7596e6041a88b2528ad63c77d1b",
            "74aec417b285462a9b37bb3729d64e0e",
            "c32aac148ca04074952123b11c7d8541",
            "4aed91d2b0f34ffeb3a1ad0480f4a2cb",
            "cff95cdb25f64a82aec75f4bcfe7c4be",
            "a7f71017080a439fb0cc07d26d387b02",
            "4b75b0da6c014be7b869887b70b1b988",
            "98a27189980e4175afc7d30440a15748",
            "8e4c7734988647e49925b6fa9bd2711e",
            "90ccb6c0b41745c3b5fe0468c8ac5a20",
            "6ded08d4d860498e80f2f7a709005bae",
            "e22aaa8e0a95431e95cc9bab4deab8e3",
            "c285114ca4414bdebe37923637f2b241",
            "d4c9ef84d4a14448ac6073c0caae0528",
            "03ea6ca0940e49f393e4b2945ec42bea",
            "7ae693dce6a049b4a0bd5fdf97ce5e94",
            "ef9574e3fea44e99a0404e223be05c14",
            "854cd6199d9342588c2edf8321316150",
            "d1dd1c2d9e8b4e45a7472461694280d0"
          ]
        },
        "id": "5an95485pdMx",
        "outputId": "9e22d8ae-2b82-49b4-8f2d-2a99d26f77c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa79ede2f6de49b68f6b976b0e7fb479",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b22a4c7953e435fb45f2755b0729673",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf3545f4245d427abd68f740796c663f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2265f83daca14eccb98005d82f6c6f2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e7b512341bc4f70b0fcaed9e02c1045",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fcfef4bf9c6454fab74b2c64ef77656",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import gc\n",
        "\n",
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:\n",
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-base')\n",
        "model = AutoModel.from_pretrained('intfloat/multilingual-e5-base').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t852gbd_pixi",
        "outputId": "8b777f29-85f7-4741-ed4f-2ac08e7c16e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[73.9798, 75.9833, 77.4119,  ..., 79.6367, 78.5389, 77.7805]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for result in result_list:\n",
        "    query = []\n",
        "    passages = []\n",
        "    query.append(f\"query: {result['query']}\")\n",
        "    for matched_item in result['matched_items']:\n",
        "        passages.append(f\"passage: {matched_item['metadata']}\")\n",
        "    # print(query)\n",
        "    input_texts = query + passages\n",
        "    batch_dict = tokenizer(\n",
        "        input_texts,\n",
        "        max_length=128,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    batch_dict = {key: value.to(device) for key, value in batch_dict.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    scores = (embeddings[:1] @ embeddings[1:].T) * 100\n",
        "    print(scores)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf27V7mOtF9n",
        "outputId": "7f51170c-ae70-43d4-c024-094b18d4308e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "B0BP6WWSBD\n",
            "Rank 1: Score = 84.28, Item ID = B09D2TRSHM, Is Real Item: False\n",
            "Rank 2: Score = 83.96, Item ID = B0B6BD13Q9, Is Real Item: False\n",
            "Rank 3: Score = 83.87, Item ID = B0BP6WWSBD, Is Real Item: True\n",
            "Rank 4: Score = 83.87, Item ID = B0BP6WWSBD, Is Real Item: True\n",
            "Rank 5: Score = 83.67, Item ID = B0B464RB6B, Is Real Item: False\n",
            "Rank 6: Score = 83.42, Item ID = B0C8V52BLR, Is Real Item: False\n",
            "Rank 7: Score = 83.36, Item ID = B0C5H87577, Is Real Item: False\n",
            "Rank 8: Score = 83.31, Item ID = B0B451WX1G, Is Real Item: False\n",
            "Rank 9: Score = 83.30, Item ID = B09F35NTYT, Is Real Item: False\n",
            "Rank 10: Score = 83.30, Item ID = B09F35NTYT, Is Real Item: False\n",
            "Rank 11: Score = 83.02, Item ID = B0923LNLK7, Is Real Item: False\n",
            "Rank 12: Score = 82.97, Item ID = B07JLTMQJT, Is Real Item: False\n",
            "Rank 13: Score = 82.81, Item ID = B085C2HMQP, Is Real Item: False\n",
            "Rank 14: Score = 82.76, Item ID = B08R2N5SDX, Is Real Item: False\n",
            "Rank 15: Score = 82.76, Item ID = B0B9MZZ96T, Is Real Item: False\n",
            "Rank 16: Score = 82.74, Item ID = B09LB1BHLB, Is Real Item: False\n",
            "Rank 17: Score = 82.69, Item ID = B07BFH9WZ7, Is Real Item: False\n",
            "Rank 18: Score = 82.47, Item ID = B0BZH7NHG4, Is Real Item: False\n",
            "Rank 19: Score = 82.31, Item ID = B0BK8DQ4H1, Is Real Item: False\n",
            "Rank 20: Score = 82.04, Item ID = B0BFQ4YG6Z, Is Real Item: False\n",
            "Rank 21: Score = 81.84, Item ID = B09WV6GTB3, Is Real Item: False\n",
            "Rank 22: Score = 81.66, Item ID = B008HOTC3M, Is Real Item: False\n",
            "Rank 23: Score = 81.58, Item ID = B0BBQNYLNP, Is Real Item: False\n",
            "Rank 24: Score = 81.45, Item ID = B09ZTSZKD1, Is Real Item: False\n",
            "Rank 25: Score = 81.25, Item ID = B0BY9NPPJT, Is Real Item: False\n",
            "Rank 26: Score = 81.19, Item ID = B097RWW2PX, Is Real Item: False\n",
            "Rank 27: Score = 81.07, Item ID = B0B6BMNQ53, Is Real Item: False\n",
            "Rank 28: Score = 81.04, Item ID = B07D3PVBJ4, Is Real Item: False\n",
            "Rank 29: Score = 80.98, Item ID = B09ZQKV4N6, Is Real Item: False\n",
            "Rank 30: Score = 80.95, Item ID = B08CHDB7ZZ, Is Real Item: False\n",
            "Rank 31: Score = 80.93, Item ID = B09CPNS1VY, Is Real Item: False\n",
            "Rank 32: Score = 80.82, Item ID = B09P9VWZJ1, Is Real Item: False\n",
            "Rank 33: Score = 80.76, Item ID = B0BRN9Z14V, Is Real Item: False\n",
            "Rank 34: Score = 80.75, Item ID = B0C7QDD8GQ, Is Real Item: False\n",
            "Rank 35: Score = 80.74, Item ID = B0C3QPNZ2L, Is Real Item: False\n",
            "Rank 36: Score = 80.69, Item ID = B09MLHLXDG, Is Real Item: False\n",
            "Rank 37: Score = 80.68, Item ID = B0855C9BGS, Is Real Item: False\n",
            "Rank 38: Score = 80.68, Item ID = B07PLNZQBQ, Is Real Item: False\n",
            "Rank 39: Score = 80.62, Item ID = B0B6CSZVPZ, Is Real Item: False\n",
            "Rank 40: Score = 80.59, Item ID = B09PYLNX9Z, Is Real Item: False\n",
            "Rank 41: Score = 80.56, Item ID = B09HGG2MC3, Is Real Item: False\n",
            "Rank 42: Score = 80.54, Item ID = B0BJK7RLSF, Is Real Item: False\n",
            "Rank 43: Score = 80.54, Item ID = B09VSDJSRP, Is Real Item: False\n",
            "Rank 44: Score = 80.54, Item ID = B0C6DMWBWR, Is Real Item: False\n",
            "Rank 45: Score = 80.51, Item ID = B09SHNYJTM, Is Real Item: False\n",
            "Rank 46: Score = 80.50, Item ID = B0BP8H9FZZ, Is Real Item: False\n",
            "Rank 47: Score = 80.48, Item ID = B0B1Q899WQ, Is Real Item: False\n",
            "Rank 48: Score = 80.44, Item ID = B088S9FSHP, Is Real Item: False\n",
            "Rank 49: Score = 80.42, Item ID = B0B4689MYZ, Is Real Item: False\n",
            "Rank 50: Score = 80.41, Item ID = B0C66WW1FK, Is Real Item: False\n",
            "Rank 51: Score = 80.40, Item ID = B0B153K3WR, Is Real Item: False\n",
            "Rank 52: Score = 80.36, Item ID = B09W318F3C, Is Real Item: False\n",
            "Rank 53: Score = 80.36, Item ID = B092DT5ZNT, Is Real Item: False\n",
            "Rank 54: Score = 80.35, Item ID = B0C7QDXT6R, Is Real Item: False\n",
            "Rank 55: Score = 80.33, Item ID = B09VKHRPDH, Is Real Item: False\n",
            "Rank 56: Score = 80.31, Item ID = B09BG43VQ8, Is Real Item: False\n",
            "Rank 57: Score = 80.28, Item ID = B0C54BTFGQ, Is Real Item: False\n",
            "Rank 58: Score = 80.22, Item ID = B09QPNP762, Is Real Item: False\n",
            "Rank 59: Score = 80.22, Item ID = B01LLWKXV6, Is Real Item: False\n",
            "Rank 60: Score = 80.22, Item ID = B0CGYPPPT3, Is Real Item: False\n",
            "Rank 61: Score = 80.20, Item ID = B08HYH6TJ6, Is Real Item: False\n",
            "Rank 62: Score = 80.13, Item ID = B0BXKG2JPS, Is Real Item: False\n",
            "Rank 63: Score = 80.12, Item ID = B00204O7EY, Is Real Item: False\n",
            "Rank 64: Score = 80.11, Item ID = B0BJZFNC8B, Is Real Item: False\n",
            "Rank 65: Score = 80.10, Item ID = B082QJ7H1R, Is Real Item: False\n",
            "Rank 66: Score = 80.08, Item ID = B07PGHXXVF, Is Real Item: False\n",
            "Rank 67: Score = 80.06, Item ID = B095PCLG59, Is Real Item: False\n",
            "Rank 68: Score = 80.05, Item ID = B081ZFQSR5, Is Real Item: False\n",
            "Rank 69: Score = 80.04, Item ID = B0C4T6RPWP, Is Real Item: False\n",
            "Rank 70: Score = 80.04, Item ID = B0BPCC4RQ9, Is Real Item: False\n",
            "Rank 71: Score = 80.04, Item ID = B0C4V5WL3V, Is Real Item: False\n",
            "Rank 72: Score = 80.04, Item ID = B09WSQBGPJ, Is Real Item: False\n",
            "Rank 73: Score = 80.00, Item ID = B09ZK74QVQ, Is Real Item: False\n",
            "Rank 74: Score = 80.00, Item ID = B0BLSLSBF6, Is Real Item: False\n",
            "Rank 75: Score = 79.98, Item ID = B0BD481G3B, Is Real Item: False\n",
            "Rank 76: Score = 79.97, Item ID = B09BKHDKNV, Is Real Item: False\n",
            "Rank 77: Score = 79.97, Item ID = B095HN6M3J, Is Real Item: False\n",
            "Rank 78: Score = 79.97, Item ID = B074HW532B, Is Real Item: False\n",
            "Rank 79: Score = 79.96, Item ID = B0C73GJQMY, Is Real Item: False\n",
            "Rank 80: Score = 79.95, Item ID = B09S361GZV, Is Real Item: False\n",
            "Rank 81: Score = 79.95, Item ID = B002Y35O5W, Is Real Item: False\n",
            "Rank 82: Score = 79.93, Item ID = B09N7535Z8, Is Real Item: False\n",
            "Rank 83: Score = 79.93, Item ID = B089D58W54, Is Real Item: False\n",
            "Rank 84: Score = 79.93, Item ID = B0BG23DP2X, Is Real Item: False\n",
            "Rank 85: Score = 79.88, Item ID = B07RS51G64, Is Real Item: False\n",
            "Rank 86: Score = 79.87, Item ID = B09FSNP1X6, Is Real Item: False\n",
            "Rank 87: Score = 79.86, Item ID = B09DPBBZF6, Is Real Item: False\n",
            "Rank 88: Score = 79.86, Item ID = B09Y5MHBQ8, Is Real Item: False\n",
            "Rank 89: Score = 79.85, Item ID = B07HPF1M83, Is Real Item: False\n",
            "Rank 90: Score = 79.85, Item ID = B0C5SDR15L, Is Real Item: False\n",
            "Rank 91: Score = 79.85, Item ID = B0C5SDR15L, Is Real Item: False\n",
            "Rank 92: Score = 79.83, Item ID = B08NK5HXQ3, Is Real Item: False\n",
            "Rank 93: Score = 79.81, Item ID = B09VKZS849, Is Real Item: False\n",
            "Rank 94: Score = 79.80, Item ID = B00652G4TS, Is Real Item: False\n",
            "Rank 95: Score = 79.80, Item ID = B0BSQNHHSH, Is Real Item: False\n",
            "Rank 96: Score = 79.79, Item ID = B09XWSRLT4, Is Real Item: False\n",
            "Rank 97: Score = 79.79, Item ID = B0BRBZK4XD, Is Real Item: False\n",
            "Rank 98: Score = 79.78, Item ID = B0C32ZZVYK, Is Real Item: False\n",
            "Rank 99: Score = 79.76, Item ID = B0BFQ6YND8, Is Real Item: False\n",
            "Rank 100: Score = 79.76, Item ID = B08Y97BK7N, Is Real Item: False\n",
            "Rank 101: Score = 79.75, Item ID = B09QFND19V, Is Real Item: False\n",
            "Rank 102: Score = 79.73, Item ID = B0C1HPMDS1, Is Real Item: False\n",
            "Rank 103: Score = 79.73, Item ID = B0C1HPMDS1, Is Real Item: False\n",
            "Rank 104: Score = 79.73, Item ID = B09PV9JC8R, Is Real Item: False\n",
            "Rank 105: Score = 79.72, Item ID = B07PQXDQJB, Is Real Item: False\n",
            "Rank 106: Score = 79.72, Item ID = B0B8SMMLHP, Is Real Item: False\n",
            "Rank 107: Score = 79.71, Item ID = B08V6MJ2NR, Is Real Item: False\n",
            "Rank 108: Score = 79.70, Item ID = B0BTT784FZ, Is Real Item: False\n",
            "Rank 109: Score = 79.69, Item ID = B0C2Z4KLT1, Is Real Item: False\n",
            "Rank 110: Score = 79.69, Item ID = B06Y2G7WLK, Is Real Item: False\n",
            "Rank 111: Score = 79.69, Item ID = B0BM48Q1YW, Is Real Item: False\n",
            "Rank 112: Score = 79.69, Item ID = B094VDLDVY, Is Real Item: False\n",
            "Rank 113: Score = 79.68, Item ID = B09XV3CS8M, Is Real Item: False\n",
            "Rank 114: Score = 79.66, Item ID = B09W211J91, Is Real Item: False\n",
            "Rank 115: Score = 79.66, Item ID = B094D3M28L, Is Real Item: False\n",
            "Rank 116: Score = 79.66, Item ID = B0012Q4IPY, Is Real Item: False\n",
            "Rank 117: Score = 79.66, Item ID = B0811Q41XY, Is Real Item: False\n",
            "Rank 118: Score = 79.66, Item ID = B0C6GM6K8S, Is Real Item: False\n",
            "Rank 119: Score = 79.66, Item ID = B0B4JSZNB6, Is Real Item: False\n",
            "Rank 120: Score = 79.65, Item ID = B08PKYPJFB, Is Real Item: False\n",
            "Rank 121: Score = 79.64, Item ID = B086MN8MZW, Is Real Item: False\n",
            "Rank 122: Score = 79.64, Item ID = B09SB9T4ZY, Is Real Item: False\n",
            "Rank 123: Score = 79.63, Item ID = B0BX9LKF7M, Is Real Item: False\n",
            "Rank 124: Score = 79.63, Item ID = B0CCCB2CP2, Is Real Item: False\n",
            "Rank 125: Score = 79.62, Item ID = B0BKNKR4K4, Is Real Item: False\n",
            "Rank 126: Score = 79.61, Item ID = B07DPVDD3F, Is Real Item: False\n",
            "Rank 127: Score = 79.60, Item ID = B09Z2623DX, Is Real Item: False\n",
            "Rank 128: Score = 79.60, Item ID = B0B6VSR11M, Is Real Item: False\n",
            "Rank 129: Score = 79.58, Item ID = B0BY4Z89ML, Is Real Item: False\n",
            "Rank 130: Score = 79.57, Item ID = B09J4346YF, Is Real Item: False\n",
            "Rank 131: Score = 79.57, Item ID = B08L7TTSY9, Is Real Item: False\n",
            "Rank 132: Score = 79.55, Item ID = B071F1KPPX, Is Real Item: False\n",
            "Rank 133: Score = 79.55, Item ID = B088LJ43MV, Is Real Item: False\n",
            "Rank 134: Score = 79.55, Item ID = B09N79S3WR, Is Real Item: False\n",
            "Rank 135: Score = 79.55, Item ID = B0BBLBH3WV, Is Real Item: False\n",
            "Rank 136: Score = 79.54, Item ID = B08XNCGP54, Is Real Item: False\n",
            "Rank 137: Score = 79.53, Item ID = B0C6QQC382, Is Real Item: False\n",
            "Rank 138: Score = 79.53, Item ID = B0BQNBNS5K, Is Real Item: False\n",
            "Rank 139: Score = 79.53, Item ID = B08RMSJXHL, Is Real Item: False\n",
            "Rank 140: Score = 79.51, Item ID = B0BZ1FQ7H7, Is Real Item: False\n",
            "Rank 141: Score = 79.51, Item ID = B0BFX4SC26, Is Real Item: False\n",
            "Rank 142: Score = 79.51, Item ID = B0BY2QHRLK, Is Real Item: False\n",
            "Rank 143: Score = 79.50, Item ID = B099Y42WDK, Is Real Item: False\n",
            "Rank 144: Score = 79.49, Item ID = B0B8MG2M6M, Is Real Item: False\n",
            "Rank 145: Score = 79.48, Item ID = B0C5S3HZNF, Is Real Item: False\n",
            "Rank 146: Score = 79.47, Item ID = B07K1Y51Y9, Is Real Item: False\n",
            "Rank 147: Score = 79.47, Item ID = B0BWJNQBGD, Is Real Item: False\n",
            "Rank 148: Score = 79.45, Item ID = B0C2BW92YH, Is Real Item: False\n",
            "Rank 149: Score = 79.45, Item ID = B088183BKS, Is Real Item: False\n",
            "Rank 150: Score = 79.45, Item ID = B0C23NDXD8, Is Real Item: False\n",
            "Rank 151: Score = 79.44, Item ID = B0BNT8P4LW, Is Real Item: False\n",
            "Rank 152: Score = 79.43, Item ID = B0B56LGJRP, Is Real Item: False\n",
            "Rank 153: Score = 79.43, Item ID = B0B4W419V4, Is Real Item: False\n",
            "Rank 154: Score = 79.43, Item ID = B00MPGSLLW, Is Real Item: False\n",
            "Rank 155: Score = 79.42, Item ID = B09NNDJS2R, Is Real Item: False\n",
            "Rank 156: Score = 79.41, Item ID = B0969P7WRM, Is Real Item: False\n",
            "Rank 157: Score = 79.40, Item ID = B0BZTWDFFP, Is Real Item: False\n",
            "Rank 158: Score = 79.40, Item ID = B0C7B9YSL2, Is Real Item: False\n",
            "Rank 159: Score = 79.40, Item ID = B073XDR7KC, Is Real Item: False\n",
            "Rank 160: Score = 79.40, Item ID = B09XWCTJMW, Is Real Item: False\n",
            "Rank 161: Score = 79.40, Item ID = B09XWCTJMW, Is Real Item: False\n",
            "Rank 162: Score = 79.39, Item ID = B0044FPNIG, Is Real Item: False\n",
            "Rank 163: Score = 79.39, Item ID = B0B7DBF4FD, Is Real Item: False\n",
            "Rank 164: Score = 79.39, Item ID = B076814SN1, Is Real Item: False\n",
            "Rank 165: Score = 79.38, Item ID = B010Y1U1JO, Is Real Item: False\n",
            "Rank 166: Score = 79.38, Item ID = B097T9LSRB, Is Real Item: False\n",
            "Rank 167: Score = 79.38, Item ID = B0BXT8HXPD, Is Real Item: False\n",
            "Rank 168: Score = 79.38, Item ID = B0B28BDZFZ, Is Real Item: False\n",
            "Rank 169: Score = 79.38, Item ID = B0792R5KJF, Is Real Item: False\n",
            "Rank 170: Score = 79.38, Item ID = B098B345RH, Is Real Item: False\n",
            "Rank 171: Score = 79.37, Item ID = B0B6VQRVRC, Is Real Item: False\n",
            "Rank 172: Score = 79.37, Item ID = B07983QSXT, Is Real Item: False\n",
            "Rank 173: Score = 79.36, Item ID = B0172LQDPA, Is Real Item: False\n",
            "Rank 174: Score = 79.36, Item ID = B0B7BPG8X6, Is Real Item: False\n",
            "Rank 175: Score = 79.35, Item ID = B09LXXXHRQ, Is Real Item: False\n",
            "Rank 176: Score = 79.35, Item ID = B07JGYWXFQ, Is Real Item: False\n",
            "Rank 177: Score = 79.35, Item ID = B01N23GRYD, Is Real Item: False\n",
            "Rank 178: Score = 79.34, Item ID = B09TB4GPRJ, Is Real Item: False\n",
            "Rank 179: Score = 79.33, Item ID = B0BKSQ4T37, Is Real Item: False\n",
            "Rank 180: Score = 79.32, Item ID = B0BG2VGZG9, Is Real Item: False\n",
            "Rank 181: Score = 79.32, Item ID = B09VSX1ZWX, Is Real Item: False\n",
            "Rank 182: Score = 79.32, Item ID = B094VQ88X2, Is Real Item: False\n",
            "Rank 183: Score = 79.32, Item ID = B0C2K9V7ZR, Is Real Item: False\n",
            "Rank 184: Score = 79.31, Item ID = B09N3FGQTH, Is Real Item: False\n",
            "Rank 185: Score = 79.31, Item ID = B07K4Q9HS1, Is Real Item: False\n",
            "Rank 186: Score = 79.31, Item ID = B000EFFS4Y, Is Real Item: False\n",
            "Rank 187: Score = 79.30, Item ID = B0B183G11R, Is Real Item: False\n",
            "Rank 188: Score = 79.30, Item ID = B00KS6JM0U, Is Real Item: False\n",
            "Rank 189: Score = 79.30, Item ID = B0B53GP63V, Is Real Item: False\n",
            "Rank 190: Score = 79.30, Item ID = B0BQ6RWJLW, Is Real Item: False\n",
            "Rank 191: Score = 79.30, Item ID = B00L7V1REE, Is Real Item: False\n",
            "Rank 192: Score = 79.29, Item ID = B00PP6QZ80, Is Real Item: False\n",
            "Rank 193: Score = 79.29, Item ID = B08LH1SVBJ, Is Real Item: False\n",
            "Rank 194: Score = 79.29, Item ID = B0B8VTTBDK, Is Real Item: False\n",
            "Rank 195: Score = 79.29, Item ID = B08MQVFTNS, Is Real Item: False\n",
            "Rank 196: Score = 79.28, Item ID = B082J2KF3H, Is Real Item: False\n",
            "Rank 197: Score = 79.28, Item ID = B094JJMWRG, Is Real Item: False\n",
            "Rank 198: Score = 79.27, Item ID = B09PVFYJSP, Is Real Item: False\n",
            "Rank 199: Score = 79.27, Item ID = B0B4ZN1PLW, Is Real Item: False\n",
            "Rank 200: Score = 79.27, Item ID = B09S54NXN4, Is Real Item: False\n",
            "Rank 201: Score = 79.26, Item ID = B08Y93M3N3, Is Real Item: False\n",
            "Rank 202: Score = 79.26, Item ID = B07S9RJTF9, Is Real Item: False\n",
            "Rank 203: Score = 79.26, Item ID = B000NZB60U, Is Real Item: False\n",
            "Rank 204: Score = 79.26, Item ID = B0BW4MJBXP, Is Real Item: False\n",
            "Rank 205: Score = 79.26, Item ID = B07H717RSV, Is Real Item: False\n",
            "Rank 206: Score = 79.25, Item ID = B0949MX825, Is Real Item: False\n",
            "Rank 207: Score = 79.25, Item ID = B07YSX2821, Is Real Item: False\n",
            "Rank 208: Score = 79.25, Item ID = B08FJDJHM8, Is Real Item: False\n",
            "Rank 209: Score = 79.25, Item ID = B08FJDJHM8, Is Real Item: False\n",
            "Rank 210: Score = 79.25, Item ID = B07WS6HRY1, Is Real Item: False\n",
            "Rank 211: Score = 79.24, Item ID = B07W46BX31, Is Real Item: False\n",
            "Rank 212: Score = 79.24, Item ID = B07W46BX31, Is Real Item: False\n",
            "Rank 213: Score = 79.24, Item ID = B093GGT7Y7, Is Real Item: False\n",
            "Rank 214: Score = 79.23, Item ID = B0B8Z4SHC3, Is Real Item: False\n",
            "Rank 215: Score = 79.23, Item ID = B0B8CD25WH, Is Real Item: False\n",
            "Rank 216: Score = 79.23, Item ID = B0BQWMMNKQ, Is Real Item: False\n",
            "Rank 217: Score = 79.23, Item ID = B01MRUKFQ8, Is Real Item: False\n",
            "Rank 218: Score = 79.22, Item ID = B0BY8FK656, Is Real Item: False\n",
            "Rank 219: Score = 79.22, Item ID = B09R3J7HKT, Is Real Item: False\n",
            "Rank 220: Score = 79.22, Item ID = B0C711Z9RF, Is Real Item: False\n",
            "Rank 221: Score = 79.21, Item ID = B0C23DV3SD, Is Real Item: False\n",
            "Rank 222: Score = 79.21, Item ID = B0BVVB4SX4, Is Real Item: False\n",
            "Rank 223: Score = 79.21, Item ID = B06VVBSFTF, Is Real Item: False\n",
            "Rank 224: Score = 79.21, Item ID = B0C4GY5QJP, Is Real Item: False\n",
            "Rank 225: Score = 79.20, Item ID = B08DV772BL, Is Real Item: False\n",
            "Rank 226: Score = 79.20, Item ID = B07QRY6ZCM, Is Real Item: False\n",
            "Rank 227: Score = 79.20, Item ID = B09C5CKWMV, Is Real Item: False\n",
            "Rank 228: Score = 79.19, Item ID = B07KWF1RJJ, Is Real Item: False\n",
            "Rank 229: Score = 79.19, Item ID = B0CFZPQ17R, Is Real Item: False\n",
            "Rank 230: Score = 79.19, Item ID = B0CFZPQ17R, Is Real Item: False\n",
            "Rank 231: Score = 79.18, Item ID = B0BQJ19HLQ, Is Real Item: False\n",
            "Rank 232: Score = 79.18, Item ID = B0C6F5W1RV, Is Real Item: False\n",
            "Rank 233: Score = 79.18, Item ID = B093TQTHV7, Is Real Item: False\n",
            "Rank 234: Score = 79.18, Item ID = B0B9MF3334, Is Real Item: False\n",
            "Rank 235: Score = 79.17, Item ID = B08L14GDWJ, Is Real Item: False\n",
            "Rank 236: Score = 79.17, Item ID = B015MMA1Q8, Is Real Item: False\n",
            "Rank 237: Score = 79.17, Item ID = B0C4ML8FB3, Is Real Item: False\n",
            "Rank 238: Score = 79.17, Item ID = B00XVQ7KEO, Is Real Item: False\n",
            "Rank 239: Score = 79.17, Item ID = B00R6DGSAK, Is Real Item: False\n",
            "Rank 240: Score = 79.16, Item ID = B09Z47C9MD, Is Real Item: False\n",
            "Rank 241: Score = 79.16, Item ID = B09N5QHX7M, Is Real Item: False\n",
            "Rank 242: Score = 79.16, Item ID = B0B8S39Z7V, Is Real Item: False\n",
            "Rank 243: Score = 79.16, Item ID = B093WMF7NW, Is Real Item: False\n",
            "Rank 244: Score = 79.16, Item ID = B0BQZSF1P4, Is Real Item: False\n",
            "Rank 245: Score = 79.15, Item ID = B0BN833CNL, Is Real Item: False\n",
            "Rank 246: Score = 79.15, Item ID = B08NCHPM7M, Is Real Item: False\n",
            "Rank 247: Score = 79.14, Item ID = B09R1TYNP9, Is Real Item: False\n",
            "Rank 248: Score = 79.14, Item ID = B0C372DYSP, Is Real Item: False\n",
            "Rank 249: Score = 79.14, Item ID = B08KH81W9Q, Is Real Item: False\n",
            "Rank 250: Score = 79.13, Item ID = B0932RRQ4M, Is Real Item: False\n",
            "Rank 251: Score = 79.13, Item ID = B01D3QEK4E, Is Real Item: False\n",
            "Rank 252: Score = 79.13, Item ID = B00TKPAHWM, Is Real Item: False\n",
            "Rank 253: Score = 79.13, Item ID = B07KVCFT2K, Is Real Item: False\n",
            "Rank 254: Score = 79.12, Item ID = B082STNSD9, Is Real Item: False\n",
            "Rank 255: Score = 79.12, Item ID = B0C1FPFTG2, Is Real Item: False\n",
            "Rank 256: Score = 79.12, Item ID = B09FF615JH, Is Real Item: False\n",
            "Rank 257: Score = 79.12, Item ID = B09P2T3X5F, Is Real Item: False\n",
            "Rank 258: Score = 79.12, Item ID = B09P2T3X5F, Is Real Item: False\n",
            "Rank 259: Score = 79.11, Item ID = B0BNNRWZJ2, Is Real Item: False\n",
            "Rank 260: Score = 79.11, Item ID = B0BL1FMQ7W, Is Real Item: False\n",
            "Rank 261: Score = 79.10, Item ID = B0875N9XF8, Is Real Item: False\n",
            "Rank 262: Score = 79.10, Item ID = B092R36QFD, Is Real Item: False\n",
            "Rank 263: Score = 79.10, Item ID = B0734QN8KR, Is Real Item: False\n",
            "Rank 264: Score = 79.10, Item ID = B075CZCTXM, Is Real Item: False\n",
            "Rank 265: Score = 79.10, Item ID = B0BY7VZ12H, Is Real Item: False\n",
            "Rank 266: Score = 79.10, Item ID = B07FB9ZGWJ, Is Real Item: False\n",
            "Rank 267: Score = 79.10, Item ID = B08RP6P1QX, Is Real Item: False\n",
            "Rank 268: Score = 79.09, Item ID = B09TDJB1Z1, Is Real Item: False\n",
            "Rank 269: Score = 79.09, Item ID = B088X4XBB9, Is Real Item: False\n",
            "Rank 270: Score = 79.09, Item ID = B0CB91P3XY, Is Real Item: False\n",
            "Rank 271: Score = 79.08, Item ID = B093HCK586, Is Real Item: False\n",
            "Rank 272: Score = 79.08, Item ID = B08F37P7H3, Is Real Item: False\n",
            "Rank 273: Score = 79.08, Item ID = B09N1VNWF3, Is Real Item: False\n",
            "Rank 274: Score = 79.07, Item ID = B08RBL1X8S, Is Real Item: False\n",
            "Rank 275: Score = 79.07, Item ID = B07FDW6ZQ8, Is Real Item: False\n",
            "Rank 276: Score = 79.07, Item ID = B07FDW6ZQ8, Is Real Item: False\n",
            "Rank 277: Score = 79.07, Item ID = B09MHXVVC7, Is Real Item: False\n",
            "Rank 278: Score = 79.06, Item ID = B00EYWHOBS, Is Real Item: False\n",
            "Rank 279: Score = 79.06, Item ID = B09SYZ7PZ2, Is Real Item: False\n",
            "Rank 280: Score = 79.06, Item ID = B0CGV93978, Is Real Item: False\n",
            "Rank 281: Score = 79.06, Item ID = B06XRZW1LD, Is Real Item: False\n",
            "Rank 282: Score = 79.05, Item ID = B07J46LD5F, Is Real Item: False\n",
            "Rank 283: Score = 79.05, Item ID = B008N3JT8A, Is Real Item: False\n",
            "Rank 284: Score = 79.05, Item ID = B099J97DMD, Is Real Item: False\n",
            "Rank 285: Score = 79.05, Item ID = B07PG6RXLN, Is Real Item: False\n",
            "Rank 286: Score = 79.04, Item ID = B0B6BHTJ12, Is Real Item: False\n",
            "Rank 287: Score = 79.04, Item ID = B092PVCQQP, Is Real Item: False\n",
            "Rank 288: Score = 79.04, Item ID = B0B74NVY9P, Is Real Item: False\n",
            "Rank 289: Score = 79.03, Item ID = B0C6356B31, Is Real Item: False\n",
            "Rank 290: Score = 79.03, Item ID = B0BJ5X2KG2, Is Real Item: False\n",
            "Rank 291: Score = 79.03, Item ID = B0C67LY8QM, Is Real Item: False\n",
            "Rank 292: Score = 79.03, Item ID = B0BFGV2CDB, Is Real Item: False\n",
            "Rank 293: Score = 79.03, Item ID = B01B3JZWDQ, Is Real Item: False\n",
            "Rank 294: Score = 79.03, Item ID = B07Q4RCLL1, Is Real Item: False\n",
            "Rank 295: Score = 79.03, Item ID = B09K7K9BCH, Is Real Item: False\n",
            "Rank 296: Score = 79.03, Item ID = B08GC3ZSDW, Is Real Item: False\n",
            "Rank 297: Score = 79.02, Item ID = B00IY3YLCI, Is Real Item: False\n",
            "Rank 298: Score = 79.02, Item ID = B0CH9LBJBL, Is Real Item: False\n",
            "Rank 299: Score = 79.02, Item ID = B0C68PRTZ4, Is Real Item: False\n",
            "Rank 300: Score = 79.01, Item ID = B0BKSXM8VN, Is Real Item: False\n",
            "Rank 301: Score = 79.01, Item ID = B08YDL85W8, Is Real Item: False\n",
            "Rank 302: Score = 79.00, Item ID = B09BYKJ2HC, Is Real Item: False\n",
            "Rank 303: Score = 79.00, Item ID = B07STLQ4P9, Is Real Item: False\n",
            "Rank 304: Score = 79.00, Item ID = B0B8T8L8TY, Is Real Item: False\n",
            "Rank 305: Score = 79.00, Item ID = B0B7DKYXWR, Is Real Item: False\n",
            "Rank 306: Score = 79.00, Item ID = B09B9MBSJZ, Is Real Item: False\n",
            "Rank 307: Score = 79.00, Item ID = B0B387GVVC, Is Real Item: False\n",
            "Rank 308: Score = 79.00, Item ID = B0B387GVVC, Is Real Item: False\n",
            "Rank 309: Score = 79.00, Item ID = B08TCH7NLW, Is Real Item: False\n",
            "Rank 310: Score = 79.00, Item ID = B09PHP2452, Is Real Item: False\n",
            "Rank 311: Score = 79.00, Item ID = B09PHP2452, Is Real Item: False\n",
            "Rank 312: Score = 78.99, Item ID = B07R4J9446, Is Real Item: False\n",
            "Rank 313: Score = 78.99, Item ID = B0BNVH8973, Is Real Item: False\n",
            "Rank 314: Score = 78.99, Item ID = B07B8YJLGL, Is Real Item: False\n",
            "Rank 315: Score = 78.99, Item ID = B01ARY90NQ, Is Real Item: False\n",
            "Rank 316: Score = 78.99, Item ID = B0BZ7KXXW8, Is Real Item: False\n",
            "Rank 317: Score = 78.98, Item ID = B09ZDFJHDN, Is Real Item: False\n",
            "Rank 318: Score = 78.97, Item ID = B01N67G7ZY, Is Real Item: False\n",
            "Rank 319: Score = 78.97, Item ID = B0BNVFFZN6, Is Real Item: False\n",
            "Rank 320: Score = 78.97, Item ID = B00Y1HRMFO, Is Real Item: False\n",
            "Rank 321: Score = 78.97, Item ID = B09Y5TB89Q, Is Real Item: False\n",
            "Rank 322: Score = 78.97, Item ID = B09Y5TB89Q, Is Real Item: False\n",
            "Rank 323: Score = 78.97, Item ID = B0B8QBTS8D, Is Real Item: False\n",
            "Rank 324: Score = 78.96, Item ID = B0B4XBXN17, Is Real Item: False\n",
            "Rank 325: Score = 78.96, Item ID = B0B979H59S, Is Real Item: False\n",
            "Rank 326: Score = 78.95, Item ID = B08HMGMXSH, Is Real Item: False\n",
            "Rank 327: Score = 78.95, Item ID = B09V12ZSBV, Is Real Item: False\n",
            "Rank 328: Score = 78.95, Item ID = B07RVFG9N5, Is Real Item: False\n",
            "Rank 329: Score = 78.95, Item ID = B0C28FCPH3, Is Real Item: False\n",
            "Rank 330: Score = 78.94, Item ID = B09PYBGVSQ, Is Real Item: False\n",
            "Rank 331: Score = 78.94, Item ID = B09CHHLJ1H, Is Real Item: False\n",
            "Rank 332: Score = 78.94, Item ID = B0C5T94ZYF, Is Real Item: False\n",
            "Rank 333: Score = 78.94, Item ID = B0BCX21N52, Is Real Item: False\n",
            "Rank 334: Score = 78.93, Item ID = B07F5QBRSF, Is Real Item: False\n",
            "Rank 335: Score = 78.93, Item ID = B0BLCVXGP2, Is Real Item: False\n",
            "Rank 336: Score = 78.93, Item ID = B0028QGTVS, Is Real Item: False\n",
            "Rank 337: Score = 78.92, Item ID = B0B7XTX768, Is Real Item: False\n",
            "Rank 338: Score = 78.92, Item ID = B07H899LT7, Is Real Item: False\n",
            "Rank 339: Score = 78.92, Item ID = B0BS17YCM2, Is Real Item: False\n",
            "Rank 340: Score = 78.92, Item ID = B08VNPFX2S, Is Real Item: False\n",
            "Rank 341: Score = 78.92, Item ID = B0BT1KWZKH, Is Real Item: False\n",
            "Rank 342: Score = 78.91, Item ID = B075Q2SSKX, Is Real Item: False\n",
            "Rank 343: Score = 78.91, Item ID = B09Z1RGVPN, Is Real Item: False\n",
            "Rank 344: Score = 78.91, Item ID = B09MLM7BQJ, Is Real Item: False\n",
            "Rank 345: Score = 78.91, Item ID = B00CC00RS6, Is Real Item: False\n",
            "Rank 346: Score = 78.91, Item ID = B0BM8QK64K, Is Real Item: False\n",
            "Rank 347: Score = 78.90, Item ID = B0BWCRJ6P1, Is Real Item: False\n",
            "Rank 348: Score = 78.90, Item ID = B09DF9XMPK, Is Real Item: False\n",
            "Rank 349: Score = 78.90, Item ID = B0B8RN3BGY, Is Real Item: False\n",
            "Rank 350: Score = 78.90, Item ID = B09QLSKYY3, Is Real Item: False\n",
            "Rank 351: Score = 78.89, Item ID = B0BBLZQ3MT, Is Real Item: False\n",
            "Rank 352: Score = 78.89, Item ID = B07S1ML3RM, Is Real Item: False\n",
            "Rank 353: Score = 78.89, Item ID = B01M3VQHAR, Is Real Item: False\n",
            "Rank 354: Score = 78.89, Item ID = B0C7RCZD9Q, Is Real Item: False\n",
            "Rank 355: Score = 78.89, Item ID = B08RDK83LB, Is Real Item: False\n",
            "Rank 356: Score = 78.88, Item ID = B0B5CS7NZG, Is Real Item: False\n",
            "Rank 357: Score = 78.88, Item ID = B087KVTTHP, Is Real Item: False\n",
            "Rank 358: Score = 78.88, Item ID = B09XMBLWSY, Is Real Item: False\n",
            "Rank 359: Score = 78.88, Item ID = B0BFQHVJHD, Is Real Item: False\n",
            "Rank 360: Score = 78.88, Item ID = B08BXTLS6F, Is Real Item: False\n",
            "Rank 361: Score = 78.88, Item ID = B07HSS8FFF, Is Real Item: False\n",
            "Rank 362: Score = 78.87, Item ID = B09NLR5GNY, Is Real Item: False\n",
            "Rank 363: Score = 78.87, Item ID = B01ICC6QF0, Is Real Item: False\n",
            "Rank 364: Score = 78.87, Item ID = B08M41FX48, Is Real Item: False\n",
            "Rank 365: Score = 78.87, Item ID = B08M41FX48, Is Real Item: False\n",
            "Rank 366: Score = 78.87, Item ID = B08Z5RY9VD, Is Real Item: False\n",
            "Rank 367: Score = 78.87, Item ID = B0BL3K74FS, Is Real Item: False\n",
            "Rank 368: Score = 78.86, Item ID = B093GTJQ6D, Is Real Item: False\n",
            "Rank 369: Score = 78.85, Item ID = B0943KLW9P, Is Real Item: False\n",
            "Rank 370: Score = 78.85, Item ID = B08H4C234W, Is Real Item: False\n",
            "Rank 371: Score = 78.85, Item ID = B09D3FX6TX, Is Real Item: False\n",
            "Rank 372: Score = 78.85, Item ID = B0922SKH8S, Is Real Item: False\n",
            "Rank 373: Score = 78.85, Item ID = B08JZ9CM5Y, Is Real Item: False\n",
            "Rank 374: Score = 78.85, Item ID = B09KRL8FML, Is Real Item: False\n",
            "Rank 375: Score = 78.85, Item ID = B09FCVLKPQ, Is Real Item: False\n",
            "Rank 376: Score = 78.84, Item ID = B07RB7GLJH, Is Real Item: False\n",
            "Rank 377: Score = 78.84, Item ID = B07SX75TDS, Is Real Item: False\n",
            "Rank 378: Score = 78.83, Item ID = B08RZ24ZC4, Is Real Item: False\n",
            "Rank 379: Score = 78.83, Item ID = B07X1Z8JR6, Is Real Item: False\n",
            "Rank 380: Score = 78.83, Item ID = B083TP31T6, Is Real Item: False\n",
            "Rank 381: Score = 78.83, Item ID = B09HZVX4GC, Is Real Item: False\n",
            "Rank 382: Score = 78.82, Item ID = B098NJN9K1, Is Real Item: False\n",
            "Rank 383: Score = 78.82, Item ID = B08BCLMSS3, Is Real Item: False\n",
            "Rank 384: Score = 78.82, Item ID = B0BRQ5PL3Z, Is Real Item: False\n",
            "Rank 385: Score = 78.82, Item ID = B06XTP3HDG, Is Real Item: False\n",
            "Rank 386: Score = 78.82, Item ID = B084GDTCT6, Is Real Item: False\n",
            "Rank 387: Score = 78.81, Item ID = B09HPYMLTS, Is Real Item: False\n",
            "Rank 388: Score = 78.81, Item ID = B0BB192PXK, Is Real Item: False\n",
            "Rank 389: Score = 78.81, Item ID = B0BKLCFRKN, Is Real Item: False\n",
            "Rank 390: Score = 78.81, Item ID = B09R4NRGVD, Is Real Item: False\n",
            "Rank 391: Score = 78.81, Item ID = B00BYH6C1E, Is Real Item: False\n",
            "Rank 392: Score = 78.81, Item ID = B00BYH6C1E, Is Real Item: False\n",
            "Rank 393: Score = 78.81, Item ID = B0C7BLM5WX, Is Real Item: False\n",
            "Rank 394: Score = 78.81, Item ID = B09NFRPWMY, Is Real Item: False\n",
            "Rank 395: Score = 78.80, Item ID = B0967QT47K, Is Real Item: False\n",
            "Rank 396: Score = 78.80, Item ID = B09QKT726Q, Is Real Item: False\n",
            "Rank 397: Score = 78.79, Item ID = B0BWDY68XZ, Is Real Item: False\n",
            "Rank 398: Score = 78.79, Item ID = B0CBDFL2KJ, Is Real Item: False\n",
            "Rank 399: Score = 78.79, Item ID = B07T9N2GLS, Is Real Item: False\n",
            "Rank 400: Score = 78.79, Item ID = B0BHY59CS7, Is Real Item: False\n",
            "Rank 401: Score = 78.79, Item ID = B08ZK3KJ7K, Is Real Item: False\n",
            "Rank 402: Score = 78.77, Item ID = B0B1WFHP5Q, Is Real Item: False\n",
            "Rank 403: Score = 78.77, Item ID = B00H6QR8D8, Is Real Item: False\n",
            "Rank 404: Score = 78.77, Item ID = B0B3MJMPMM, Is Real Item: False\n",
            "Rank 405: Score = 78.77, Item ID = B09LRFW4W5, Is Real Item: False\n",
            "Rank 406: Score = 78.77, Item ID = B0C59HR89D, Is Real Item: False\n",
            "Rank 407: Score = 78.76, Item ID = B0BYSDZXRR, Is Real Item: False\n",
            "Rank 408: Score = 78.76, Item ID = B0BYSDZXRR, Is Real Item: False\n",
            "Rank 409: Score = 78.76, Item ID = B0C7C43LVB, Is Real Item: False\n",
            "Rank 410: Score = 78.76, Item ID = B09474MX51, Is Real Item: False\n",
            "Rank 411: Score = 78.76, Item ID = B09MD9YBQ5, Is Real Item: False\n",
            "Rank 412: Score = 78.75, Item ID = B09P5DZ5LM, Is Real Item: False\n",
            "Rank 413: Score = 78.75, Item ID = B0CDRS3H9Y, Is Real Item: False\n",
            "Rank 414: Score = 78.75, Item ID = B0B9M871G2, Is Real Item: False\n",
            "Rank 415: Score = 78.75, Item ID = B07S2B8C46, Is Real Item: False\n",
            "Rank 416: Score = 78.75, Item ID = B0BWY148RL, Is Real Item: False\n",
            "Rank 417: Score = 78.74, Item ID = B0B3XS96SB, Is Real Item: False\n",
            "Rank 418: Score = 78.74, Item ID = B08N1GRNQD, Is Real Item: False\n",
            "Rank 419: Score = 78.74, Item ID = B08MZYVDY9, Is Real Item: False\n",
            "Rank 420: Score = 78.74, Item ID = B083YZ7WCR, Is Real Item: False\n",
            "Rank 421: Score = 78.74, Item ID = B0BWCM5F1T, Is Real Item: False\n",
            "Rank 422: Score = 78.74, Item ID = B09TGXTQK7, Is Real Item: False\n",
            "Rank 423: Score = 78.74, Item ID = B0C4TDRF86, Is Real Item: False\n",
            "Rank 424: Score = 78.74, Item ID = B0BX6H6PKR, Is Real Item: False\n",
            "Rank 425: Score = 78.73, Item ID = B09QZGR93X, Is Real Item: False\n",
            "Rank 426: Score = 78.73, Item ID = B0BHDM6K55, Is Real Item: False\n",
            "Rank 427: Score = 78.73, Item ID = B0BVZJHWJ3, Is Real Item: False\n",
            "Rank 428: Score = 78.73, Item ID = B079X5SDPS, Is Real Item: False\n",
            "Rank 429: Score = 78.73, Item ID = B0BZ3DV3ZP, Is Real Item: False\n",
            "Rank 430: Score = 78.73, Item ID = B00CKDGP0O, Is Real Item: False\n",
            "Rank 431: Score = 78.73, Item ID = B07MBQV4JK, Is Real Item: False\n",
            "Rank 432: Score = 78.72, Item ID = B0B3D96MN6, Is Real Item: False\n",
            "Rank 433: Score = 78.72, Item ID = B0C1T3DRTR, Is Real Item: False\n",
            "Rank 434: Score = 78.72, Item ID = B08CV379G9, Is Real Item: False\n",
            "Rank 435: Score = 78.72, Item ID = B088FJBGJ4, Is Real Item: False\n",
            "Rank 436: Score = 78.71, Item ID = B0725RRRS5, Is Real Item: False\n",
            "Rank 437: Score = 78.71, Item ID = B08TWJ6KMN, Is Real Item: False\n",
            "Rank 438: Score = 78.71, Item ID = B098PYB8XG, Is Real Item: False\n",
            "Rank 439: Score = 78.71, Item ID = B0CG3BDWYT, Is Real Item: False\n",
            "Rank 440: Score = 78.71, Item ID = B0C27SCXG6, Is Real Item: False\n",
            "Rank 441: Score = 78.71, Item ID = B0BCGCTFVN, Is Real Item: False\n",
            "Rank 442: Score = 78.71, Item ID = B09TTKH8K6, Is Real Item: False\n",
            "Rank 443: Score = 78.70, Item ID = B0B8G8S976, Is Real Item: False\n",
            "Rank 444: Score = 78.70, Item ID = B07LB8Z1ZN, Is Real Item: False\n",
            "Rank 445: Score = 78.70, Item ID = B0BP9CHQK9, Is Real Item: False\n",
            "Rank 446: Score = 78.70, Item ID = B0CBDH57WG, Is Real Item: False\n",
            "Rank 447: Score = 78.70, Item ID = B075ZP5TJX, Is Real Item: False\n",
            "Rank 448: Score = 78.69, Item ID = B08HM9P1VD, Is Real Item: False\n",
            "Rank 449: Score = 78.69, Item ID = B09V2T9RLM, Is Real Item: False\n",
            "Rank 450: Score = 78.69, Item ID = B087F3HCX2, Is Real Item: False\n",
            "Rank 451: Score = 78.69, Item ID = B005HPVXYK, Is Real Item: False\n",
            "Rank 452: Score = 78.69, Item ID = B0CG9XLNXQ, Is Real Item: False\n",
            "Rank 453: Score = 78.68, Item ID = B088SYWH3Y, Is Real Item: False\n",
            "Rank 454: Score = 78.68, Item ID = B0BJQ2GYNN, Is Real Item: False\n",
            "Rank 455: Score = 78.68, Item ID = B07WDNK25J, Is Real Item: False\n",
            "Rank 456: Score = 78.68, Item ID = B00004RBDW, Is Real Item: False\n",
            "Rank 457: Score = 78.68, Item ID = B0BQR5F2MP, Is Real Item: False\n",
            "Rank 458: Score = 78.68, Item ID = B0BQR5F2MP, Is Real Item: False\n",
            "Rank 459: Score = 78.68, Item ID = B0BLH57T65, Is Real Item: False\n",
            "Rank 460: Score = 78.68, Item ID = B08NV7QH5T, Is Real Item: False\n",
            "Rank 461: Score = 78.68, Item ID = B0B2RG2YHL, Is Real Item: False\n",
            "Rank 462: Score = 78.67, Item ID = B0BYN6LQ81, Is Real Item: False\n",
            "Rank 463: Score = 78.67, Item ID = B09HRVFFFC, Is Real Item: False\n",
            "Rank 464: Score = 78.67, Item ID = B0BT27PDVV, Is Real Item: False\n",
            "Rank 465: Score = 78.67, Item ID = B09M3JLSVF, Is Real Item: False\n",
            "Rank 466: Score = 78.67, Item ID = B0BV1L1LTG, Is Real Item: False\n",
            "Rank 467: Score = 78.67, Item ID = B0C4D3TKRN, Is Real Item: False\n",
            "Rank 468: Score = 78.66, Item ID = B09NLMQ24D, Is Real Item: False\n",
            "Rank 469: Score = 78.66, Item ID = B07JCKNQSZ, Is Real Item: False\n",
            "Rank 470: Score = 78.66, Item ID = B075F214K1, Is Real Item: False\n",
            "Rank 471: Score = 78.66, Item ID = B08X1MSNNX, Is Real Item: False\n",
            "Rank 472: Score = 78.65, Item ID = B09LXN9TMM, Is Real Item: False\n",
            "Rank 473: Score = 78.65, Item ID = B09LXN9TMM, Is Real Item: False\n",
            "Rank 474: Score = 78.65, Item ID = B0CGWLSZGT, Is Real Item: False\n",
            "Rank 475: Score = 78.65, Item ID = B07KZSYHQG, Is Real Item: False\n",
            "Rank 476: Score = 78.65, Item ID = B0CCNRF72S, Is Real Item: False\n",
            "Rank 477: Score = 78.64, Item ID = B09HGM44DV, Is Real Item: False\n",
            "Rank 478: Score = 78.64, Item ID = B0B5ZRM249, Is Real Item: False\n",
            "Rank 479: Score = 78.64, Item ID = B09SJ1WM6P, Is Real Item: False\n",
            "Rank 480: Score = 78.64, Item ID = B07MP1Q3W8, Is Real Item: False\n",
            "Rank 481: Score = 78.64, Item ID = B0BYHGD4HC, Is Real Item: False\n",
            "Rank 482: Score = 78.63, Item ID = B0B4B19ZRG, Is Real Item: False\n",
            "Rank 483: Score = 78.63, Item ID = B0BTNBPTTB, Is Real Item: False\n",
            "Rank 484: Score = 78.63, Item ID = B09962CTGX, Is Real Item: False\n",
            "Rank 485: Score = 78.63, Item ID = B0BC1BHSZF, Is Real Item: False\n",
            "Rank 486: Score = 78.63, Item ID = B07GY1YR64, Is Real Item: False\n",
            "Rank 487: Score = 78.63, Item ID = B073XRSCBH, Is Real Item: False\n",
            "Rank 488: Score = 78.62, Item ID = B09MB445SJ, Is Real Item: False\n",
            "Rank 489: Score = 78.62, Item ID = B0BSB5CCCC, Is Real Item: False\n",
            "Rank 490: Score = 78.62, Item ID = B0919H77FL, Is Real Item: False\n",
            "Rank 491: Score = 78.62, Item ID = B08H4RSXT1, Is Real Item: False\n",
            "Rank 492: Score = 78.62, Item ID = B07ZYLHVSM, Is Real Item: False\n",
            "Rank 493: Score = 78.61, Item ID = B00HDF9EXE, Is Real Item: False\n",
            "Rank 494: Score = 78.61, Item ID = B094C2NKBV, Is Real Item: False\n",
            "Rank 495: Score = 78.61, Item ID = B098N7QMGC, Is Real Item: False\n",
            "Rank 496: Score = 78.61, Item ID = B07FKTP7L9, Is Real Item: False\n",
            "Rank 497: Score = 78.61, Item ID = B076J5HCWP, Is Real Item: False\n",
            "Rank 498: Score = 78.61, Item ID = B07NV4QVS4, Is Real Item: False\n",
            "Rank 499: Score = 78.61, Item ID = B07Z37QDYV, Is Real Item: False\n",
            "Rank 500: Score = 78.61, Item ID = B09MLF93FW, Is Real Item: False\n",
            "Rank 501: Score = 78.60, Item ID = B0C3WV37SZ, Is Real Item: False\n",
            "Rank 502: Score = 78.60, Item ID = B07MVW593Y, Is Real Item: False\n",
            "Rank 503: Score = 78.59, Item ID = B0BZNTVYF8, Is Real Item: False\n",
            "Rank 504: Score = 78.59, Item ID = B07H9FVG3Z, Is Real Item: False\n",
            "Rank 505: Score = 78.59, Item ID = B0BYDC56K9, Is Real Item: False\n",
            "Rank 506: Score = 78.59, Item ID = B00BJMF832, Is Real Item: False\n",
            "Rank 507: Score = 78.59, Item ID = B0BNTNKY4Y, Is Real Item: False\n",
            "Rank 508: Score = 78.59, Item ID = B0BBGH6ZH1, Is Real Item: False\n",
            "Rank 509: Score = 78.59, Item ID = B093LSY57L, Is Real Item: False\n",
            "Rank 510: Score = 78.59, Item ID = B09D76KH3C, Is Real Item: False\n",
            "Rank 511: Score = 78.59, Item ID = B0BBLX4VKT, Is Real Item: False\n",
            "Rank 512: Score = 78.59, Item ID = B08HPGZTJ8, Is Real Item: False\n",
            "Rank 513: Score = 78.59, Item ID = B00VQLBSR6, Is Real Item: False\n",
            "Rank 514: Score = 78.59, Item ID = B0BTP5V6KD, Is Real Item: False\n",
            "Rank 515: Score = 78.58, Item ID = B0B6QTLFNY, Is Real Item: False\n",
            "Rank 516: Score = 78.58, Item ID = B097M4LLJN, Is Real Item: False\n",
            "Rank 517: Score = 78.58, Item ID = B0B5X417FH, Is Real Item: False\n",
            "Rank 518: Score = 78.58, Item ID = B0BLYFRGQ9, Is Real Item: False\n",
            "Rank 519: Score = 78.58, Item ID = B0B7BM6PGQ, Is Real Item: False\n",
            "Rank 520: Score = 78.58, Item ID = B0BGLPGZPV, Is Real Item: False\n",
            "Rank 521: Score = 78.58, Item ID = B0BMQ4PGVB, Is Real Item: False\n",
            "Rank 522: Score = 78.57, Item ID = B0BSG8G8MD, Is Real Item: False\n",
            "Rank 523: Score = 78.57, Item ID = B0BTHLHGPV, Is Real Item: False\n",
            "Rank 524: Score = 78.57, Item ID = B0BQF9TJFB, Is Real Item: False\n",
            "Rank 525: Score = 78.57, Item ID = B0BQ797J3W, Is Real Item: False\n",
            "Rank 526: Score = 78.57, Item ID = B0B6KJRXL4, Is Real Item: False\n",
            "Rank 527: Score = 78.57, Item ID = B098JP1TVR, Is Real Item: False\n",
            "Rank 528: Score = 78.56, Item ID = B0C65X2XPQ, Is Real Item: False\n",
            "Rank 529: Score = 78.56, Item ID = B09SHFL8LD, Is Real Item: False\n",
            "Rank 530: Score = 78.55, Item ID = B08BXSTFWK, Is Real Item: False\n",
            "Rank 531: Score = 78.55, Item ID = B093YJRZ8H, Is Real Item: False\n",
            "Rank 532: Score = 78.55, Item ID = B09QF1XZPF, Is Real Item: False\n",
            "Rank 533: Score = 78.55, Item ID = B082MCSRC7, Is Real Item: False\n",
            "Rank 534: Score = 78.55, Item ID = B09YNWXQJ5, Is Real Item: False\n",
            "Rank 535: Score = 78.54, Item ID = B07D9BY5M2, Is Real Item: False\n",
            "Rank 536: Score = 78.54, Item ID = B07SYV9PDK, Is Real Item: False\n",
            "Rank 537: Score = 78.54, Item ID = B08JMG94X4, Is Real Item: False\n",
            "Rank 538: Score = 78.54, Item ID = B0B2K8XQFZ, Is Real Item: False\n",
            "Rank 539: Score = 78.54, Item ID = B002NGUVGM, Is Real Item: False\n",
            "Rank 540: Score = 78.54, Item ID = B0C96TTQYG, Is Real Item: False\n",
            "Rank 541: Score = 78.54, Item ID = B07Y3Z9SRQ, Is Real Item: False\n",
            "Rank 542: Score = 78.53, Item ID = B09292H22C, Is Real Item: False\n",
            "Rank 543: Score = 78.53, Item ID = B0BVR4Q3XM, Is Real Item: False\n",
            "Rank 544: Score = 78.53, Item ID = B09QS1DBR9, Is Real Item: False\n",
            "Rank 545: Score = 78.53, Item ID = B0BLZ84M4Y, Is Real Item: False\n",
            "Rank 546: Score = 78.53, Item ID = B09YVL4JB1, Is Real Item: False\n",
            "Rank 547: Score = 78.52, Item ID = B0CBBM43VF, Is Real Item: False\n",
            "Rank 548: Score = 78.52, Item ID = B0B72MKSCN, Is Real Item: False\n",
            "Rank 549: Score = 78.52, Item ID = B09D6ZDDRJ, Is Real Item: False\n",
            "Rank 550: Score = 78.52, Item ID = B0BLYWG3XB, Is Real Item: False\n",
            "Rank 551: Score = 78.52, Item ID = B07ZBM2KJ3, Is Real Item: False\n",
            "Rank 552: Score = 78.51, Item ID = B09P8S38KR, Is Real Item: False\n",
            "Rank 553: Score = 78.51, Item ID = B07QJ97BHQ, Is Real Item: False\n",
            "Rank 554: Score = 78.50, Item ID = B0BFKCJLS5, Is Real Item: False\n",
            "Rank 555: Score = 78.50, Item ID = B08LMNMMS4, Is Real Item: False\n",
            "Rank 556: Score = 78.50, Item ID = B0C1C2P853, Is Real Item: False\n",
            "Rank 557: Score = 78.50, Item ID = B0C5Y1C7JN, Is Real Item: False\n",
            "Rank 558: Score = 78.50, Item ID = B07NWDKX2N, Is Real Item: False\n",
            "Rank 559: Score = 78.50, Item ID = B09D7CHMFQ, Is Real Item: False\n",
            "Rank 560: Score = 78.50, Item ID = B0B1WQFFWF, Is Real Item: False\n",
            "Rank 561: Score = 78.50, Item ID = B0BG7ZDJGK, Is Real Item: False\n",
            "Rank 562: Score = 78.50, Item ID = B00MTAGICI, Is Real Item: False\n",
            "Rank 563: Score = 78.50, Item ID = B0C73CY9XC, Is Real Item: False\n",
            "Rank 564: Score = 78.50, Item ID = B0BV2YZ7FV, Is Real Item: False\n",
            "Rank 565: Score = 78.49, Item ID = B083414J18, Is Real Item: False\n",
            "Rank 566: Score = 78.49, Item ID = B071YBZVTL, Is Real Item: False\n",
            "Rank 567: Score = 78.49, Item ID = B0C86JBJ2F, Is Real Item: False\n",
            "Rank 568: Score = 78.49, Item ID = B00VSO3AFO, Is Real Item: False\n",
            "Rank 569: Score = 78.49, Item ID = B0C4H5528W, Is Real Item: False\n",
            "Rank 570: Score = 78.49, Item ID = B0B3XMH1F2, Is Real Item: False\n",
            "Rank 571: Score = 78.48, Item ID = B0BGYYS9N4, Is Real Item: False\n",
            "Rank 572: Score = 78.48, Item ID = B00CXXSIJM, Is Real Item: False\n",
            "Rank 573: Score = 78.48, Item ID = B091DSKBGV, Is Real Item: False\n",
            "Rank 574: Score = 78.48, Item ID = B08GZ7LCMN, Is Real Item: False\n",
            "Rank 575: Score = 78.48, Item ID = B09WDTNPTW, Is Real Item: False\n",
            "Rank 576: Score = 78.47, Item ID = B0B7X1CF5Q, Is Real Item: False\n",
            "Rank 577: Score = 78.47, Item ID = B0BQHMKX9S, Is Real Item: False\n",
            "Rank 578: Score = 78.47, Item ID = B0BD876MQT, Is Real Item: False\n",
            "Rank 579: Score = 78.47, Item ID = B0BYHCYTNK, Is Real Item: False\n",
            "Rank 580: Score = 78.47, Item ID = B0BFQ5NMVW, Is Real Item: False\n",
            "Rank 581: Score = 78.47, Item ID = B09BH738J6, Is Real Item: False\n",
            "Rank 582: Score = 78.47, Item ID = B087T3PRX8, Is Real Item: False\n",
            "Rank 583: Score = 78.47, Item ID = B00QZH82BQ, Is Real Item: False\n",
            "Rank 584: Score = 78.46, Item ID = B09QVDCS3B, Is Real Item: False\n",
            "Rank 585: Score = 78.46, Item ID = B096W66H67, Is Real Item: False\n",
            "Rank 586: Score = 78.46, Item ID = B0BTDPQVXV, Is Real Item: False\n",
            "Rank 587: Score = 78.46, Item ID = B0BNK5W7TF, Is Real Item: False\n",
            "Rank 588: Score = 78.46, Item ID = B08R1F4PNX, Is Real Item: False\n",
            "Rank 589: Score = 78.46, Item ID = B09XBDHLHY, Is Real Item: False\n",
            "Rank 590: Score = 78.45, Item ID = B06XCR8RF3, Is Real Item: False\n",
            "Rank 591: Score = 78.45, Item ID = B0BRNW3536, Is Real Item: False\n",
            "Rank 592: Score = 78.45, Item ID = B0925W678F, Is Real Item: False\n",
            "Rank 593: Score = 78.44, Item ID = B0BSVNHFRG, Is Real Item: False\n",
            "Rank 594: Score = 78.44, Item ID = B09L4M2FBS, Is Real Item: False\n",
            "Rank 595: Score = 78.44, Item ID = B09XK13GZQ, Is Real Item: False\n",
            "Rank 596: Score = 78.44, Item ID = B0B9GJWZ4P, Is Real Item: False\n",
            "Rank 597: Score = 78.44, Item ID = B0B45889W1, Is Real Item: False\n",
            "Rank 598: Score = 78.44, Item ID = B08P3CS8TS, Is Real Item: False\n",
            "Rank 599: Score = 78.44, Item ID = B09S1VMFWZ, Is Real Item: False\n",
            "Rank 600: Score = 78.44, Item ID = B09YY7DHN1, Is Real Item: False\n",
            "Rank 601: Score = 78.43, Item ID = B09YCVSMRW, Is Real Item: False\n",
            "Rank 602: Score = 78.43, Item ID = B0B7DX3MV7, Is Real Item: False\n",
            "Rank 603: Score = 78.43, Item ID = B0B7DX3MV7, Is Real Item: False\n",
            "Rank 604: Score = 78.43, Item ID = B0B9NFXL37, Is Real Item: False\n",
            "Rank 605: Score = 78.42, Item ID = B0BWX9GW2K, Is Real Item: False\n",
            "Rank 606: Score = 78.42, Item ID = B07WVCVTS6, Is Real Item: False\n",
            "Rank 607: Score = 78.42, Item ID = B0BRQL9VZY, Is Real Item: False\n",
            "Rank 608: Score = 78.42, Item ID = B07HK7J83X, Is Real Item: False\n",
            "Rank 609: Score = 78.42, Item ID = B0BBL7R77T, Is Real Item: False\n",
            "Rank 610: Score = 78.42, Item ID = B01BPENQHI, Is Real Item: False\n",
            "Rank 611: Score = 78.41, Item ID = B0BVXYJ1C3, Is Real Item: False\n",
            "Rank 612: Score = 78.41, Item ID = B09FX41543, Is Real Item: False\n",
            "Rank 613: Score = 78.41, Item ID = B09VRRQ4R4, Is Real Item: False\n",
            "Rank 614: Score = 78.41, Item ID = B092J7JXS9, Is Real Item: False\n",
            "Rank 615: Score = 78.41, Item ID = B09N6MF3P9, Is Real Item: False\n",
            "Rank 616: Score = 78.41, Item ID = B0BBVBFL57, Is Real Item: False\n",
            "Rank 617: Score = 78.40, Item ID = B0B9JPTR7M, Is Real Item: False\n",
            "Rank 618: Score = 78.40, Item ID = B0BGK6VX5Y, Is Real Item: False\n",
            "Rank 619: Score = 78.40, Item ID = B01HQAH2NO, Is Real Item: False\n",
            "Rank 620: Score = 78.40, Item ID = B09L162QBF, Is Real Item: False\n",
            "Rank 621: Score = 78.40, Item ID = B083K1PV27, Is Real Item: False\n",
            "Rank 622: Score = 78.40, Item ID = B0BSSHSP5T, Is Real Item: False\n",
            "Rank 623: Score = 78.39, Item ID = B0BDFWDMRK, Is Real Item: False\n",
            "Rank 624: Score = 78.39, Item ID = B0B9B51SW7, Is Real Item: False\n",
            "Rank 625: Score = 78.39, Item ID = B0828QRKXR, Is Real Item: False\n",
            "Rank 626: Score = 78.39, Item ID = B07PZSRMH4, Is Real Item: False\n",
            "Rank 627: Score = 78.39, Item ID = B0BLSSWB57, Is Real Item: False\n",
            "Rank 628: Score = 78.39, Item ID = B078GK73TK, Is Real Item: False\n",
            "Rank 629: Score = 78.38, Item ID = B0BSDKTV94, Is Real Item: False\n",
            "Rank 630: Score = 78.38, Item ID = B09YVK7J45, Is Real Item: False\n",
            "Rank 631: Score = 78.38, Item ID = B08WY4PXLT, Is Real Item: False\n",
            "Rank 632: Score = 78.38, Item ID = B08WY4PXLT, Is Real Item: False\n",
            "Rank 633: Score = 78.38, Item ID = B08WY4PXLT, Is Real Item: False\n",
            "Rank 634: Score = 78.38, Item ID = B0BN8K4P7P, Is Real Item: False\n",
            "Rank 635: Score = 78.38, Item ID = B07V58Q1JL, Is Real Item: False\n",
            "Rank 636: Score = 78.37, Item ID = B08NXG7FN4, Is Real Item: False\n",
            "Rank 637: Score = 78.37, Item ID = B0834JP97K, Is Real Item: False\n",
            "Rank 638: Score = 78.37, Item ID = B083973R7X, Is Real Item: False\n",
            "Rank 639: Score = 78.37, Item ID = B0C5HFZ45L, Is Real Item: False\n",
            "Rank 640: Score = 78.37, Item ID = B09XWWB725, Is Real Item: False\n",
            "Rank 641: Score = 78.37, Item ID = B09F8SMW6Q, Is Real Item: False\n",
            "Rank 642: Score = 78.36, Item ID = B09LVF3LNX, Is Real Item: False\n",
            "Rank 643: Score = 78.36, Item ID = B0148O64JE, Is Real Item: False\n",
            "Rank 644: Score = 78.36, Item ID = B086VN65CL, Is Real Item: False\n",
            "Rank 645: Score = 78.36, Item ID = B07YDB31G4, Is Real Item: False\n",
            "Rank 646: Score = 78.36, Item ID = B09Z6S1JF6, Is Real Item: False\n",
            "Rank 647: Score = 78.36, Item ID = B09HTRNG1T, Is Real Item: False\n",
            "Rank 648: Score = 78.35, Item ID = B07QBFTP8C, Is Real Item: False\n",
            "Rank 649: Score = 78.35, Item ID = B079P1Y5W8, Is Real Item: False\n",
            "Rank 650: Score = 78.35, Item ID = B0BW3Y9BCB, Is Real Item: False\n",
            "Rank 651: Score = 78.35, Item ID = B09XBBB9SM, Is Real Item: False\n",
            "Rank 652: Score = 78.34, Item ID = B0B2RNGPWR, Is Real Item: False\n",
            "Rank 653: Score = 78.34, Item ID = B01HQFVIZC, Is Real Item: False\n",
            "Rank 654: Score = 78.34, Item ID = B0C6R6BP58, Is Real Item: False\n",
            "Rank 655: Score = 78.34, Item ID = B09159VC3W, Is Real Item: False\n",
            "Rank 656: Score = 78.33, Item ID = B0BY8ZDV11, Is Real Item: False\n",
            "Rank 657: Score = 78.33, Item ID = B0BKKRGFC6, Is Real Item: False\n",
            "Rank 658: Score = 78.32, Item ID = B09JNPNZC9, Is Real Item: False\n",
            "Rank 659: Score = 78.32, Item ID = B08YJR63XJ, Is Real Item: False\n",
            "Rank 660: Score = 78.32, Item ID = B08XPG8FR5, Is Real Item: False\n",
            "Rank 661: Score = 78.32, Item ID = B0C72Z4RKF, Is Real Item: False\n",
            "Rank 662: Score = 78.32, Item ID = B0BQYJYB8H, Is Real Item: False\n",
            "Rank 663: Score = 78.32, Item ID = B08JCQCTT8, Is Real Item: False\n",
            "Rank 664: Score = 78.31, Item ID = B07D8TLQ6L, Is Real Item: False\n",
            "Rank 665: Score = 78.31, Item ID = B00LD1FCFS, Is Real Item: False\n",
            "Rank 666: Score = 78.31, Item ID = B00WML8TEO, Is Real Item: False\n",
            "Rank 667: Score = 78.31, Item ID = B0B1J74326, Is Real Item: False\n",
            "Rank 668: Score = 78.31, Item ID = B0BPC8J5XX, Is Real Item: False\n",
            "Rank 669: Score = 78.31, Item ID = B072317XNY, Is Real Item: False\n",
            "Rank 670: Score = 78.30, Item ID = B08RBJ4V7Y, Is Real Item: False\n",
            "Rank 671: Score = 78.30, Item ID = B0BYZ1M2YS, Is Real Item: False\n",
            "Rank 672: Score = 78.30, Item ID = B0C23QY915, Is Real Item: False\n",
            "Rank 673: Score = 78.30, Item ID = B088LXR8PW, Is Real Item: False\n",
            "Rank 674: Score = 78.30, Item ID = B000IXRMSM, Is Real Item: False\n",
            "Rank 675: Score = 78.30, Item ID = B09MFHSJR6, Is Real Item: False\n",
            "Rank 676: Score = 78.30, Item ID = B000923524, Is Real Item: False\n",
            "Rank 677: Score = 78.29, Item ID = B09RGLZNX9, Is Real Item: False\n",
            "Rank 678: Score = 78.29, Item ID = B08CP9H8K1, Is Real Item: False\n",
            "Rank 679: Score = 78.29, Item ID = B0C5XGD8JL, Is Real Item: False\n",
            "Rank 680: Score = 78.29, Item ID = B09B51TCKS, Is Real Item: False\n",
            "Rank 681: Score = 78.29, Item ID = B09YH64N6L, Is Real Item: False\n",
            "Rank 682: Score = 78.28, Item ID = B07GYSNM7G, Is Real Item: False\n",
            "Rank 683: Score = 78.28, Item ID = B07W534ZFS, Is Real Item: False\n",
            "Rank 684: Score = 78.28, Item ID = B099MW5VTN, Is Real Item: False\n",
            "Rank 685: Score = 78.28, Item ID = B007C68PNY, Is Real Item: False\n",
            "Rank 686: Score = 78.28, Item ID = B08N18BD1R, Is Real Item: False\n",
            "Rank 687: Score = 78.28, Item ID = B07GFTNRMN, Is Real Item: False\n",
            "Rank 688: Score = 78.28, Item ID = B09PDTJ6B2, Is Real Item: False\n",
            "Rank 689: Score = 78.28, Item ID = B09NVWQ2TW, Is Real Item: False\n",
            "Rank 690: Score = 78.28, Item ID = B0BK874VSS, Is Real Item: False\n",
            "Rank 691: Score = 78.28, Item ID = B0BWM7961P, Is Real Item: False\n",
            "Rank 692: Score = 78.28, Item ID = B08QTSSGTB, Is Real Item: False\n",
            "Rank 693: Score = 78.27, Item ID = B0BRKPTYH9, Is Real Item: False\n",
            "Rank 694: Score = 78.27, Item ID = B0971W5GJK, Is Real Item: False\n",
            "Rank 695: Score = 78.27, Item ID = B091DCDBQ9, Is Real Item: False\n",
            "Rank 696: Score = 78.27, Item ID = B09LRYBVXJ, Is Real Item: False\n",
            "Rank 697: Score = 78.27, Item ID = B09V2WJSVN, Is Real Item: False\n",
            "Rank 698: Score = 78.26, Item ID = B0BQHHMDHF, Is Real Item: False\n",
            "Rank 699: Score = 78.26, Item ID = B07ND2YYMM, Is Real Item: False\n",
            "Rank 700: Score = 78.26, Item ID = B09KH9G3N8, Is Real Item: False\n",
            "Rank 701: Score = 78.26, Item ID = B09CTND5WW, Is Real Item: False\n",
            "Rank 702: Score = 78.26, Item ID = B0BB9NCZHD, Is Real Item: False\n",
            "Rank 703: Score = 78.25, Item ID = B079MJZ6DL, Is Real Item: False\n",
            "Rank 704: Score = 78.25, Item ID = B0BWFCR613, Is Real Item: False\n",
            "Rank 705: Score = 78.25, Item ID = B09292MYMY, Is Real Item: False\n",
            "Rank 706: Score = 78.25, Item ID = B07C9HXG5J, Is Real Item: False\n",
            "Rank 707: Score = 78.25, Item ID = B09D5PC4HZ, Is Real Item: False\n",
            "Rank 708: Score = 78.25, Item ID = B0BHC8WDHN, Is Real Item: False\n",
            "Rank 709: Score = 78.25, Item ID = B09DMX6TZS, Is Real Item: False\n",
            "Rank 710: Score = 78.24, Item ID = B0C5VSBNJT, Is Real Item: False\n",
            "Rank 711: Score = 78.23, Item ID = B091P9QXX7, Is Real Item: False\n",
            "Rank 712: Score = 78.23, Item ID = B09Y8YJ9LF, Is Real Item: False\n",
            "Rank 713: Score = 78.23, Item ID = B0BT3394C1, Is Real Item: False\n",
            "Rank 714: Score = 78.22, Item ID = B0BXRZBQBN, Is Real Item: False\n",
            "Rank 715: Score = 78.22, Item ID = B003AVZEZW, Is Real Item: False\n",
            "Rank 716: Score = 78.22, Item ID = B0BLMN556B, Is Real Item: False\n",
            "Rank 717: Score = 78.21, Item ID = B07F946Z1V, Is Real Item: False\n",
            "Rank 718: Score = 78.21, Item ID = B09V5B58QV, Is Real Item: False\n",
            "Rank 719: Score = 78.21, Item ID = B09W2FMZJZ, Is Real Item: False\n",
            "Rank 720: Score = 78.21, Item ID = B09NCYKKWY, Is Real Item: False\n",
            "Rank 721: Score = 78.20, Item ID = B0BSJFXT16, Is Real Item: False\n",
            "Rank 722: Score = 78.20, Item ID = B0BBMTHNV1, Is Real Item: False\n",
            "Rank 723: Score = 78.20, Item ID = B08DK1H1ZW, Is Real Item: False\n",
            "Rank 724: Score = 78.20, Item ID = B0C27BTNZR, Is Real Item: False\n",
            "Rank 725: Score = 78.20, Item ID = B07RN9WKW2, Is Real Item: False\n",
            "Rank 726: Score = 78.20, Item ID = B09KN77D8H, Is Real Item: False\n",
            "Rank 727: Score = 78.20, Item ID = B09KN84GJ9, Is Real Item: False\n",
            "Rank 728: Score = 78.20, Item ID = B09TNZL269, Is Real Item: False\n",
            "Rank 729: Score = 78.20, Item ID = B0C4TMKKD2, Is Real Item: False\n",
            "Rank 730: Score = 78.19, Item ID = B09XM3QVLL, Is Real Item: False\n",
            "Rank 731: Score = 78.19, Item ID = B0BBQ9JWLB, Is Real Item: False\n",
            "Rank 732: Score = 78.19, Item ID = B08Y64GH41, Is Real Item: False\n",
            "Rank 733: Score = 78.19, Item ID = B0BFBQZZMC, Is Real Item: False\n",
            "Rank 734: Score = 78.19, Item ID = B01ELUGNQE, Is Real Item: False\n",
            "Rank 735: Score = 78.19, Item ID = B09JRHBYYB, Is Real Item: False\n",
            "Rank 736: Score = 78.19, Item ID = B0B79MGHCK, Is Real Item: False\n",
            "Rank 737: Score = 78.19, Item ID = B0B79MGHCK, Is Real Item: False\n",
            "Rank 738: Score = 78.19, Item ID = B07W5YGZ72, Is Real Item: False\n",
            "Rank 739: Score = 78.18, Item ID = B09TL8N4MD, Is Real Item: False\n",
            "Rank 740: Score = 78.18, Item ID = B0C7HLF9YP, Is Real Item: False\n",
            "Rank 741: Score = 78.18, Item ID = B07FYJVFNK, Is Real Item: False\n",
            "Rank 742: Score = 78.18, Item ID = B0B3S88X6X, Is Real Item: False\n",
            "Rank 743: Score = 78.18, Item ID = B091YFGFSY, Is Real Item: False\n",
            "Rank 744: Score = 78.17, Item ID = B091CTF4T8, Is Real Item: False\n",
            "Rank 745: Score = 78.17, Item ID = B0C1RSHZW8, Is Real Item: False\n",
            "Rank 746: Score = 78.17, Item ID = B08R5JJB74, Is Real Item: False\n",
            "Rank 747: Score = 78.17, Item ID = B08R5JJB74, Is Real Item: False\n",
            "Rank 748: Score = 78.17, Item ID = B09WVG38YF, Is Real Item: False\n",
            "Rank 749: Score = 78.17, Item ID = B0B8Y53H88, Is Real Item: False\n",
            "Rank 750: Score = 78.17, Item ID = B09VXB6YDJ, Is Real Item: False\n",
            "Rank 751: Score = 78.17, Item ID = B08ZXNLCL9, Is Real Item: False\n",
            "Rank 752: Score = 78.16, Item ID = B081GNK55B, Is Real Item: False\n",
            "Rank 753: Score = 78.16, Item ID = B01GFVQM36, Is Real Item: False\n",
            "Rank 754: Score = 78.16, Item ID = B095T2YQ4D, Is Real Item: False\n",
            "Rank 755: Score = 78.16, Item ID = B0BP6NNCVF, Is Real Item: False\n",
            "Rank 756: Score = 78.16, Item ID = B0BF61DFK9, Is Real Item: False\n",
            "Rank 757: Score = 78.15, Item ID = B00RU8FEWO, Is Real Item: False\n",
            "Rank 758: Score = 78.15, Item ID = B0BBL4V8B3, Is Real Item: False\n",
            "Rank 759: Score = 78.15, Item ID = B0C5XDB8HJ, Is Real Item: False\n",
            "Rank 760: Score = 78.15, Item ID = B0C5XDB8HJ, Is Real Item: False\n",
            "Rank 761: Score = 78.15, Item ID = B0BGXZLXNJ, Is Real Item: False\n",
            "Rank 762: Score = 78.15, Item ID = B0B6VTVSPD, Is Real Item: False\n",
            "Rank 763: Score = 78.15, Item ID = B07Z67MMGC, Is Real Item: False\n",
            "Rank 764: Score = 78.15, Item ID = B07YCTPKMP, Is Real Item: False\n",
            "Rank 765: Score = 78.15, Item ID = B09YJPWY8V, Is Real Item: False\n",
            "Rank 766: Score = 78.15, Item ID = B0C7NFP8RJ, Is Real Item: False\n",
            "Rank 767: Score = 78.14, Item ID = B07VQ9R7SM, Is Real Item: False\n",
            "Rank 768: Score = 78.14, Item ID = B0B1912D6G, Is Real Item: False\n",
            "Rank 769: Score = 78.14, Item ID = B003DWE3OQ, Is Real Item: False\n",
            "Rank 770: Score = 78.14, Item ID = B08Y6BWBJN, Is Real Item: False\n",
            "Rank 771: Score = 78.14, Item ID = B0BGDHCYX3, Is Real Item: False\n",
            "Rank 772: Score = 78.14, Item ID = B0C6GRYG6S, Is Real Item: False\n",
            "Rank 773: Score = 78.14, Item ID = B085T68X4V, Is Real Item: False\n",
            "Rank 774: Score = 78.14, Item ID = B0BN1X5R65, Is Real Item: False\n",
            "Rank 775: Score = 78.13, Item ID = B0BZ6L12W9, Is Real Item: False\n",
            "Rank 776: Score = 78.13, Item ID = B0BH3FBGGM, Is Real Item: False\n",
            "Rank 777: Score = 78.13, Item ID = B091KW1VQ8, Is Real Item: False\n",
            "Rank 778: Score = 78.13, Item ID = B07DD68D4Q, Is Real Item: False\n",
            "Rank 779: Score = 78.13, Item ID = B0B49L58J4, Is Real Item: False\n",
            "Rank 780: Score = 78.13, Item ID = B0BC6BKXH3, Is Real Item: False\n",
            "Rank 781: Score = 78.13, Item ID = B0C11PF68H, Is Real Item: False\n",
            "Rank 782: Score = 78.13, Item ID = B09TXW49H6, Is Real Item: False\n",
            "Rank 783: Score = 78.12, Item ID = B0BLGY3MT2, Is Real Item: False\n",
            "Rank 784: Score = 78.12, Item ID = B08W3RX484, Is Real Item: False\n",
            "Rank 785: Score = 78.12, Item ID = B08HK3CJSQ, Is Real Item: False\n",
            "Rank 786: Score = 78.12, Item ID = B08HK3CJSQ, Is Real Item: False\n",
            "Rank 787: Score = 78.12, Item ID = B08HK3CJSQ, Is Real Item: False\n",
            "Rank 788: Score = 78.12, Item ID = B09FW16C26, Is Real Item: False\n",
            "Rank 789: Score = 78.12, Item ID = B0BY68Z3L1, Is Real Item: False\n",
            "Rank 790: Score = 78.12, Item ID = B08Z32TCKH, Is Real Item: False\n",
            "Rank 791: Score = 78.12, Item ID = B0C1JBCYYD, Is Real Item: False\n",
            "Rank 792: Score = 78.11, Item ID = B0B3RN1255, Is Real Item: False\n",
            "Rank 793: Score = 78.11, Item ID = B0BKPP37FV, Is Real Item: False\n",
            "Rank 794: Score = 78.11, Item ID = B0C5FMTQ7N, Is Real Item: False\n",
            "Rank 795: Score = 78.11, Item ID = B08CB1XYM1, Is Real Item: False\n",
            "Rank 796: Score = 78.11, Item ID = B09FJQH2KV, Is Real Item: False\n",
            "Rank 797: Score = 78.11, Item ID = B00P2XZBD6, Is Real Item: False\n",
            "Rank 798: Score = 78.11, Item ID = B00P2XZBD6, Is Real Item: False\n",
            "Rank 799: Score = 78.11, Item ID = B01K48VZ24, Is Real Item: False\n",
            "Rank 800: Score = 78.10, Item ID = B01C4YTI1Q, Is Real Item: False\n",
            "Rank 801: Score = 78.10, Item ID = B0BNMZXNT1, Is Real Item: False\n",
            "Rank 802: Score = 78.10, Item ID = B0BGKHK1T8, Is Real Item: False\n",
            "Rank 803: Score = 78.10, Item ID = B08PKRPDJ6, Is Real Item: False\n",
            "Rank 804: Score = 78.10, Item ID = B0BD82WZ7Z, Is Real Item: False\n",
            "Rank 805: Score = 78.10, Item ID = B01IFQ0TY2, Is Real Item: False\n",
            "Rank 806: Score = 78.10, Item ID = B0BXKWM5J7, Is Real Item: False\n",
            "Rank 807: Score = 78.09, Item ID = B09R9Q1RC1, Is Real Item: False\n",
            "Rank 808: Score = 78.09, Item ID = B07SHZQ4R1, Is Real Item: False\n",
            "Rank 809: Score = 78.09, Item ID = B0BZ7Y5VL5, Is Real Item: False\n",
            "Rank 810: Score = 78.09, Item ID = B0B7L3NS54, Is Real Item: False\n",
            "Rank 811: Score = 78.09, Item ID = B0C22WT694, Is Real Item: False\n",
            "Rank 812: Score = 78.09, Item ID = B07N7DJS85, Is Real Item: False\n",
            "Rank 813: Score = 78.09, Item ID = B0BDZ1NTF3, Is Real Item: False\n",
            "Rank 814: Score = 78.09, Item ID = B0781BR7V7, Is Real Item: False\n",
            "Rank 815: Score = 78.08, Item ID = B0C6JWRLYK, Is Real Item: False\n",
            "Rank 816: Score = 78.08, Item ID = B0BZ87VN3R, Is Real Item: False\n",
            "Rank 817: Score = 78.08, Item ID = B08T7G1421, Is Real Item: False\n",
            "Rank 818: Score = 78.08, Item ID = B0BZYRBXBS, Is Real Item: False\n",
            "Rank 819: Score = 78.08, Item ID = B07PY61N2W, Is Real Item: False\n",
            "Rank 820: Score = 78.07, Item ID = B09XL9MSKV, Is Real Item: False\n",
            "Rank 821: Score = 78.07, Item ID = B0C2TXTKKX, Is Real Item: False\n",
            "Rank 822: Score = 78.07, Item ID = B0BY81SMVD, Is Real Item: False\n",
            "Rank 823: Score = 78.07, Item ID = B0CF5CTZ1T, Is Real Item: False\n",
            "Rank 824: Score = 78.07, Item ID = B0BDMVQ5SC, Is Real Item: False\n",
            "Rank 825: Score = 78.07, Item ID = B0BTV9CRFS, Is Real Item: False\n",
            "Rank 826: Score = 78.07, Item ID = B09WDDQ5NY, Is Real Item: False\n",
            "Rank 827: Score = 78.07, Item ID = B0BKZPKK7J, Is Real Item: False\n",
            "Rank 828: Score = 78.07, Item ID = B08YJCQ23B, Is Real Item: False\n",
            "Rank 829: Score = 78.06, Item ID = B08QRNRGFH, Is Real Item: False\n",
            "Rank 830: Score = 78.06, Item ID = B08TKL1HSN, Is Real Item: False\n",
            "Rank 831: Score = 78.05, Item ID = B0B12MFGYF, Is Real Item: False\n",
            "Rank 832: Score = 78.05, Item ID = B015FVTRSO, Is Real Item: False\n",
            "Rank 833: Score = 78.05, Item ID = B0881RVY11, Is Real Item: False\n",
            "Rank 834: Score = 78.05, Item ID = B0C5QD6YZH, Is Real Item: False\n",
            "Rank 835: Score = 78.05, Item ID = B09V2ST72B, Is Real Item: False\n",
            "Rank 836: Score = 78.05, Item ID = B0BM6MZN7L, Is Real Item: False\n",
            "Rank 837: Score = 78.05, Item ID = B01D61NSUS, Is Real Item: False\n",
            "Rank 838: Score = 78.04, Item ID = B0BYCDSXYY, Is Real Item: False\n",
            "Rank 839: Score = 78.04, Item ID = B09NM8D1GM, Is Real Item: False\n",
            "Rank 840: Score = 78.04, Item ID = B084F9F2BL, Is Real Item: False\n",
            "Rank 841: Score = 78.04, Item ID = B084F9F2BL, Is Real Item: False\n",
            "Rank 842: Score = 78.04, Item ID = B084F9F2BL, Is Real Item: False\n",
            "Rank 843: Score = 78.03, Item ID = B0C5HJY4J1, Is Real Item: False\n",
            "Rank 844: Score = 78.03, Item ID = B09TN26JN9, Is Real Item: False\n",
            "Rank 845: Score = 78.03, Item ID = B0C7CGQNQY, Is Real Item: False\n",
            "Rank 846: Score = 78.03, Item ID = B00403OBSA, Is Real Item: False\n",
            "Rank 847: Score = 78.03, Item ID = B08FG1RHFV, Is Real Item: False\n",
            "Rank 848: Score = 78.02, Item ID = B01KQQDLCG, Is Real Item: False\n",
            "Rank 849: Score = 78.02, Item ID = B0C9GK4QNV, Is Real Item: False\n",
            "Rank 850: Score = 78.02, Item ID = B0BC36VPTG, Is Real Item: False\n",
            "Rank 851: Score = 78.02, Item ID = B0C7PJFBBK, Is Real Item: False\n",
            "Rank 852: Score = 78.01, Item ID = B0C1FMDWTS, Is Real Item: False\n",
            "Rank 853: Score = 78.01, Item ID = B076J8C9N8, Is Real Item: False\n",
            "Rank 854: Score = 78.01, Item ID = B0C2HN9484, Is Real Item: False\n",
            "Rank 855: Score = 78.01, Item ID = B0009H5M4S, Is Real Item: False\n",
            "Rank 856: Score = 78.01, Item ID = B0BRMP7XZX, Is Real Item: False\n",
            "Rank 857: Score = 78.01, Item ID = B09TNXRRHP, Is Real Item: False\n",
            "Rank 858: Score = 78.01, Item ID = B078T2R64C, Is Real Item: False\n",
            "Rank 859: Score = 78.01, Item ID = B0B7X5JBVV, Is Real Item: False\n",
            "Rank 860: Score = 78.01, Item ID = B0BR7VQV62, Is Real Item: False\n",
            "Rank 861: Score = 78.01, Item ID = B08KY514F3, Is Real Item: False\n",
            "Rank 862: Score = 78.01, Item ID = B0BBMB4CDC, Is Real Item: False\n",
            "Rank 863: Score = 78.01, Item ID = B09VXMGRG8, Is Real Item: False\n",
            "Rank 864: Score = 78.00, Item ID = B076SC377J, Is Real Item: False\n",
            "Rank 865: Score = 78.00, Item ID = B0BV16XCCS, Is Real Item: False\n",
            "Rank 866: Score = 78.00, Item ID = B0C9XCG48C, Is Real Item: False\n",
            "Rank 867: Score = 78.00, Item ID = B09LCX6Z2Z, Is Real Item: False\n",
            "Rank 868: Score = 78.00, Item ID = B0BM4KB4H7, Is Real Item: False\n",
            "Rank 869: Score = 78.00, Item ID = B092SHMWQZ, Is Real Item: False\n",
            "Rank 870: Score = 78.00, Item ID = B0CDWMG9XJ, Is Real Item: False\n",
            "Rank 871: Score = 78.00, Item ID = B0C5RDY5X7, Is Real Item: False\n",
            "Rank 872: Score = 78.00, Item ID = B0C2ZLM3HD, Is Real Item: False\n",
            "Rank 873: Score = 78.00, Item ID = B0195MZHBK, Is Real Item: False\n",
            "Rank 874: Score = 78.00, Item ID = B09XJDPYG4, Is Real Item: False\n",
            "Rank 875: Score = 78.00, Item ID = B09ZHT13CW, Is Real Item: False\n",
            "Rank 876: Score = 78.00, Item ID = B0BFF26721, Is Real Item: False\n",
            "Rank 877: Score = 78.00, Item ID = B0B5XZ2H3J, Is Real Item: False\n",
            "Rank 878: Score = 77.99, Item ID = B09S173CVK, Is Real Item: False\n",
            "Rank 879: Score = 77.99, Item ID = B09ZSWHWW8, Is Real Item: False\n",
            "Rank 880: Score = 77.99, Item ID = B0B1T7LDFP, Is Real Item: False\n",
            "Rank 881: Score = 77.99, Item ID = B0BK87C29Q, Is Real Item: False\n",
            "Rank 882: Score = 77.99, Item ID = B0CBLQPNVT, Is Real Item: False\n",
            "Rank 883: Score = 77.98, Item ID = B07F92BX3P, Is Real Item: False\n",
            "Rank 884: Score = 77.98, Item ID = B09YVL897J, Is Real Item: False\n",
            "Rank 885: Score = 77.98, Item ID = B09BN4YWFC, Is Real Item: False\n",
            "Rank 886: Score = 77.98, Item ID = B0B66ZKH29, Is Real Item: False\n",
            "Rank 887: Score = 77.97, Item ID = B07NJPGXT5, Is Real Item: False\n",
            "Rank 888: Score = 77.97, Item ID = B0BLRT6Y7L, Is Real Item: False\n",
            "Rank 889: Score = 77.97, Item ID = B07M68V8L8, Is Real Item: False\n",
            "Rank 890: Score = 77.97, Item ID = B099Y4DXWR, Is Real Item: False\n",
            "Rank 891: Score = 77.96, Item ID = B078T236MB, Is Real Item: False\n",
            "Rank 892: Score = 77.96, Item ID = B08MYTDLB2, Is Real Item: False\n",
            "Rank 893: Score = 77.96, Item ID = B0BR7MKHF9, Is Real Item: False\n",
            "Rank 894: Score = 77.96, Item ID = B0C33TB6YD, Is Real Item: False\n",
            "Rank 895: Score = 77.96, Item ID = B0BGT8267T, Is Real Item: False\n",
            "Rank 896: Score = 77.95, Item ID = B09KXBZ9QN, Is Real Item: False\n",
            "Rank 897: Score = 77.95, Item ID = B09GVQJVJZ, Is Real Item: False\n",
            "Rank 898: Score = 77.95, Item ID = B09GVQJVJZ, Is Real Item: False\n",
            "Rank 899: Score = 77.95, Item ID = B07GDNPS2W, Is Real Item: False\n",
            "Rank 900: Score = 77.95, Item ID = B08N195YF5, Is Real Item: False\n",
            "Rank 901: Score = 77.95, Item ID = B09V6SVL65, Is Real Item: False\n",
            "Rank 902: Score = 77.95, Item ID = B097Y4RCH1, Is Real Item: False\n",
            "Rank 903: Score = 77.94, Item ID = B0CB1WCTWW, Is Real Item: False\n",
            "Rank 904: Score = 77.94, Item ID = B0B121FSGX, Is Real Item: False\n",
            "Rank 905: Score = 77.94, Item ID = B07PWNDYD3, Is Real Item: False\n",
            "Rank 906: Score = 77.94, Item ID = B07PWNDYD3, Is Real Item: False\n",
            "Rank 907: Score = 77.94, Item ID = B073ZJC763, Is Real Item: False\n",
            "Rank 908: Score = 77.93, Item ID = B09835WGW1, Is Real Item: False\n",
            "Rank 909: Score = 77.93, Item ID = B0B5B9MB76, Is Real Item: False\n",
            "Rank 910: Score = 77.93, Item ID = B0B8M7TR2W, Is Real Item: False\n",
            "Rank 911: Score = 77.93, Item ID = B0CGJC2ZPL, Is Real Item: False\n",
            "Rank 912: Score = 77.93, Item ID = B0BFVWD3ZD, Is Real Item: False\n",
            "Rank 913: Score = 77.93, Item ID = B086R7TXX8, Is Real Item: False\n",
            "Rank 914: Score = 77.93, Item ID = B0936YKSXF, Is Real Item: False\n",
            "Rank 915: Score = 77.93, Item ID = B0B1M7NPXT, Is Real Item: False\n",
            "Rank 916: Score = 77.93, Item ID = B00CR9WWN0, Is Real Item: False\n",
            "Rank 917: Score = 77.93, Item ID = B0C7CCR7PL, Is Real Item: False\n",
            "Rank 918: Score = 77.92, Item ID = B09D3S5H57, Is Real Item: False\n",
            "Rank 919: Score = 77.92, Item ID = B0C6Y1T4HG, Is Real Item: False\n",
            "Rank 920: Score = 77.92, Item ID = B01GFO3E3Y, Is Real Item: False\n",
            "Rank 921: Score = 77.92, Item ID = B0BM5HZ2TP, Is Real Item: False\n",
            "Rank 922: Score = 77.92, Item ID = B0BM5HZ2TP, Is Real Item: False\n",
            "Rank 923: Score = 77.92, Item ID = B0BM5HZ2TP, Is Real Item: False\n",
            "Rank 924: Score = 77.92, Item ID = B002MUW202, Is Real Item: False\n",
            "Rank 925: Score = 77.92, Item ID = B0153226YW, Is Real Item: False\n",
            "Rank 926: Score = 77.92, Item ID = B09YYZ21JP, Is Real Item: False\n",
            "Rank 927: Score = 77.91, Item ID = B07MVV9DJJ, Is Real Item: False\n",
            "Rank 928: Score = 77.91, Item ID = B00KQV1B5Q, Is Real Item: False\n",
            "Rank 929: Score = 77.91, Item ID = B09TWW2BC9, Is Real Item: False\n",
            "Rank 930: Score = 77.91, Item ID = B09H6NGWYF, Is Real Item: False\n",
            "Rank 931: Score = 77.91, Item ID = B0BRWV1253, Is Real Item: False\n",
            "Rank 932: Score = 77.90, Item ID = B09M2GMLT6, Is Real Item: False\n",
            "Rank 933: Score = 77.90, Item ID = B08DKHZX49, Is Real Item: False\n",
            "Rank 934: Score = 77.90, Item ID = B09KLQKTG2, Is Real Item: False\n",
            "Rank 935: Score = 77.90, Item ID = B082LPR5Q9, Is Real Item: False\n",
            "Rank 936: Score = 77.89, Item ID = B082V4NTV3, Is Real Item: False\n",
            "Rank 937: Score = 77.89, Item ID = B0B1LP5935, Is Real Item: False\n",
            "Rank 938: Score = 77.89, Item ID = B07W21RVKD, Is Real Item: False\n",
            "Rank 939: Score = 77.89, Item ID = B09FKVXH5G, Is Real Item: False\n",
            "Rank 940: Score = 77.89, Item ID = B0B18KR1L2, Is Real Item: False\n",
            "Rank 941: Score = 77.89, Item ID = B018H74H74, Is Real Item: False\n",
            "Rank 942: Score = 77.89, Item ID = B0BY3TKNRV, Is Real Item: False\n",
            "Rank 943: Score = 77.89, Item ID = B097RJFLWZ, Is Real Item: False\n",
            "Rank 944: Score = 77.89, Item ID = B07QKNYTGK, Is Real Item: False\n",
            "Rank 945: Score = 77.89, Item ID = B0BSTK4NBZ, Is Real Item: False\n",
            "Rank 946: Score = 77.88, Item ID = B072KZLKMK, Is Real Item: False\n",
            "Rank 947: Score = 77.88, Item ID = B08JLLCG49, Is Real Item: False\n",
            "Rank 948: Score = 77.88, Item ID = B081N6WHV5, Is Real Item: False\n",
            "Rank 949: Score = 77.88, Item ID = B000UOF920, Is Real Item: False\n",
            "Rank 950: Score = 77.88, Item ID = B0BR66YW92, Is Real Item: False\n",
            "Rank 951: Score = 77.87, Item ID = B07QYZBPH1, Is Real Item: False\n",
            "Rank 952: Score = 77.87, Item ID = B08MZFPNY7, Is Real Item: False\n",
            "Rank 953: Score = 77.87, Item ID = B0B57FM57S, Is Real Item: False\n",
            "Rank 954: Score = 77.87, Item ID = B08NK1SNVR, Is Real Item: False\n",
            "Rank 955: Score = 77.87, Item ID = B09TBKB7N2, Is Real Item: False\n",
            "Rank 956: Score = 77.87, Item ID = B000CNIMSC, Is Real Item: False\n",
            "Rank 957: Score = 77.87, Item ID = B0BPSDP9YL, Is Real Item: False\n",
            "Rank 958: Score = 77.87, Item ID = B0BLH68B5R, Is Real Item: False\n",
            "Rank 959: Score = 77.87, Item ID = B08L616T2C, Is Real Item: False\n",
            "Rank 960: Score = 77.86, Item ID = B0BJ5W776D, Is Real Item: False\n",
            "Rank 961: Score = 77.86, Item ID = B09Z6CW81R, Is Real Item: False\n",
            "Rank 962: Score = 77.86, Item ID = B078S54S8Z, Is Real Item: False\n",
            "Rank 963: Score = 77.86, Item ID = B09SFRLGN4, Is Real Item: False\n",
            "Rank 964: Score = 77.86, Item ID = B008PAIWCA, Is Real Item: False\n",
            "Rank 965: Score = 77.86, Item ID = B0B3WNPZB6, Is Real Item: False\n",
            "Rank 966: Score = 77.86, Item ID = B06W5DDH35, Is Real Item: False\n",
            "Rank 967: Score = 77.85, Item ID = B07QSCVQ3R, Is Real Item: False\n",
            "Rank 968: Score = 77.85, Item ID = B0C4KSNR2Y, Is Real Item: False\n",
            "Rank 969: Score = 77.85, Item ID = B0C38RQM9Y, Is Real Item: False\n",
            "Rank 970: Score = 77.85, Item ID = B08B8ZL1KN, Is Real Item: False\n",
            "Rank 971: Score = 77.85, Item ID = B0C5KFXM2K, Is Real Item: False\n",
            "Rank 972: Score = 77.85, Item ID = B08ZH9ZXNB, Is Real Item: False\n",
            "Rank 973: Score = 77.84, Item ID = B07Y3XTBJZ, Is Real Item: False\n",
            "Rank 974: Score = 77.84, Item ID = B0CD2836S4, Is Real Item: False\n",
            "Rank 975: Score = 77.84, Item ID = B0B7P219XY, Is Real Item: False\n",
            "Rank 976: Score = 77.84, Item ID = B085WPNC29, Is Real Item: False\n",
            "Rank 977: Score = 77.84, Item ID = B0BKL1GSZL, Is Real Item: False\n",
            "Rank 978: Score = 77.84, Item ID = B091L15LLR, Is Real Item: False\n",
            "Rank 979: Score = 77.84, Item ID = B099DF293G, Is Real Item: False\n",
            "Rank 980: Score = 77.84, Item ID = B08JC9LWSQ, Is Real Item: False\n",
            "Rank 981: Score = 77.84, Item ID = B08JC9LWSQ, Is Real Item: False\n",
            "Rank 982: Score = 77.84, Item ID = B0CHBBH5PG, Is Real Item: False\n",
            "Rank 983: Score = 77.84, Item ID = B0B7XBZ59F, Is Real Item: False\n",
            "Rank 984: Score = 77.84, Item ID = B0B77CF6KJ, Is Real Item: False\n",
            "Rank 985: Score = 77.84, Item ID = B0B619FNM3, Is Real Item: False\n",
            "Rank 986: Score = 77.84, Item ID = B01HMV7B0G, Is Real Item: False\n",
            "Rank 987: Score = 77.83, Item ID = B096Z7CBMK, Is Real Item: False\n",
            "Rank 988: Score = 77.83, Item ID = B07H9YMLF9, Is Real Item: False\n",
            "Rank 989: Score = 77.83, Item ID = B07NXX4PV4, Is Real Item: False\n",
            "Rank 990: Score = 77.83, Item ID = B07QNXM4LS, Is Real Item: False\n",
            "Rank 991: Score = 77.83, Item ID = B0C443HRYY, Is Real Item: False\n",
            "Rank 992: Score = 77.82, Item ID = B0008KLNSA, Is Real Item: False\n",
            "Rank 993: Score = 77.82, Item ID = B0BJ1Y38RG, Is Real Item: False\n",
            "Rank 994: Score = 77.82, Item ID = B0056ORKPS, Is Real Item: False\n",
            "Rank 995: Score = 77.82, Item ID = B071NHY26W, Is Real Item: False\n",
            "Rank 996: Score = 77.82, Item ID = B07FRRFR47, Is Real Item: False\n",
            "Rank 997: Score = 77.82, Item ID = B083SG7ZT8, Is Real Item: False\n",
            "Rank 998: Score = 77.81, Item ID = B09G61NKC3, Is Real Item: False\n",
            "Rank 999: Score = 77.81, Item ID = B0C8JQFY2N, Is Real Item: False\n",
            "Rank 1000: Score = 77.81, Item ID = B07Q5FWQ9P, Is Real Item: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "for result in result_list:\n",
        "    query = []\n",
        "    passages = []\n",
        "    query.append(f\"query: {result['query']}\")\n",
        "\n",
        "    for matched_item in result['matched_items']:\n",
        "        passages.append(f\"passage: {matched_item['metadata']}\")\n",
        "\n",
        "    # Combine query and passages into input_texts\n",
        "    input_texts = query + passages\n",
        "\n",
        "    # Tokenize inputs\n",
        "    batch_dict = tokenizer(\n",
        "        input_texts,\n",
        "        max_length=128,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    batch_dict = {key: value.to(device) for key, value in batch_dict.items()}\n",
        "\n",
        "    # Get embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    # Compute scores\n",
        "    scores = (embeddings[:1] @ embeddings[1:].T) * 100  # Compute similarity scores\n",
        "    scores = scores.squeeze(0)  # Remove extra dimension for easier processing\n",
        "\n",
        "    # Get top-10 scores and corresponding indices\n",
        "    top_scores, top_indices = torch.topk(scores, k=1000)\n",
        "\n",
        "    # Map top scores to matched_items and check their IDs\n",
        "    top_matched_items = [result['matched_items'][idx] for idx in top_indices]\n",
        "    print(result['real_item_id'])\n",
        "    for i, matched_item in enumerate(top_matched_items):\n",
        "        item_id = matched_item['item_id']\n",
        "        is_real_item = item_id == result['real_item_id']\n",
        "        print(f\"Rank {i+1}: Score = {top_scores[i].item():.2f}, Item ID = {item_id}, Is Real Item: {is_real_item}\")\n",
        "\n",
        "    break  # Break after processing the first result (for debugging)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F5KBn0pzR4Y",
        "outputId": "b7f496a2-4c95-4ea3-dd9e-6718cc6ca00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4186\n"
          ]
        }
      ],
      "source": [
        "print(len(result_list[2]['matched_items']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "TzU0tnZ_whY4",
        "outputId": "b7065d5a-f8f7-408d-bc6e-eca938409a25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Results:   9%|█████▎                                                     | 9/100 [01:11<12:00,  7.92s/result]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 11.13 GiB. GPU 0 has a total capacty of 47.53 GiB of which 10.22 GiB is free. Process 2254516 has 306.00 MiB memory in use. Process 2265350 has 306.00 MiB memory in use. Including non-PyTorch memory, this process has 36.69 GiB memory in use. Of the allocated memory 21.75 GiB is allocated by PyTorch, and 14.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Get embeddings\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m average_pool(outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state, batch_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     33\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(embeddings, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:977\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    975\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 977\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    990\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:632\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    621\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    622\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    623\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m         output_attentions,\n\u001b[1;32m    630\u001b[0m     )\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:563\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    560\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    561\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 563\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:575\u001b[0m, in \u001b[0;36mXLMRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 575\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:474\u001b[0m, in \u001b[0;36mXLMRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    473\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 474\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/data/xiangjun/conda3/envs/env/lib/python3.8/site-packages/transformers/activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 11.13 GiB. GPU 0 has a total capacty of 47.53 GiB of which 10.22 GiB is free. Process 2254516 has 306.00 MiB memory in use. Process 2265350 has 306.00 MiB memory in use. Including non-PyTorch memory, this process has 36.69 GiB memory in use. Of the allocated memory 21.75 GiB is allocated by PyTorch, and 14.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "real_item_in_top200_count = 0\n",
        "total_results = min(100, len(result_list))\n",
        "\n",
        "for result in tqdm(result_list[:100], desc=\"Processing Results\", unit=\"result\"):\n",
        "    query = []\n",
        "    passages = []\n",
        "    query.append(f\"query: {result['query']}\")\n",
        "\n",
        "    for matched_item in result['matched_items']:\n",
        "        passages.append(f\"passage: {matched_item['metadata']}\")\n",
        "\n",
        "    # Combine query and passages into input_texts\n",
        "    input_texts = query + passages\n",
        "\n",
        "    # Tokenize inputs\n",
        "    batch_dict = tokenizer(\n",
        "        input_texts,\n",
        "        max_length=128,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    batch_dict = {key: value.to(device) for key, value in batch_dict.items()}\n",
        "\n",
        "    # Get embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    # Compute scores\n",
        "    scores = (embeddings[:1] @ embeddings[1:].T) * 100  # Compute similarity scores\n",
        "    scores = scores.squeeze(0)  # Remove extra dimension for easier processing\n",
        "\n",
        "    # Get top-10 scores and corresponding indices\n",
        "    top_scores, top_indices = torch.topk(scores, k=200)\n",
        "\n",
        "    # Map top scores to matched_items and check if real_item is in top-10\n",
        "    top_matched_items = [result['matched_items'][idx] for idx in top_indices]\n",
        "\n",
        "    # Check if real_item is in top-10\n",
        "    real_item_found = any(matched_item['item_id'] == result['real_item_id'] for matched_item in top_matched_items)\n",
        "\n",
        "    # Update count if real_item is found in top-10\n",
        "    if real_item_found:\n",
        "        real_item_in_top200_count += 1\n",
        "\n",
        "# Calculate the probability\n",
        "if total_results > 0:\n",
        "    probability = real_item_in_top200_count / total_results\n",
        "else:\n",
        "    probability = 0.0\n",
        "\n",
        "print(f\"\\nProbability of real_item appearing in top-200: {probability:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkeWTCK689St"
      },
      "outputs": [],
      "source": [
        "# extend to all results\n",
        "# do not run this\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "real_item_in_top200_count = 0\n",
        "total_results = len(result_list)\n",
        "\n",
        "for result in tqdm(result_list, desc=\"Processing Results\", unit=\"result\"):\n",
        "    query = []\n",
        "    passages = []\n",
        "    query.append(f\"query: {result['query']}\")\n",
        "\n",
        "    for matched_item in result['matched_items']:\n",
        "        passages.append(f\"passage: {matched_item['metadata']}\")\n",
        "\n",
        "    # Combine query and passages into input_texts\n",
        "    input_texts = query + passages\n",
        "\n",
        "    # Tokenize inputs\n",
        "    batch_dict = tokenizer(\n",
        "        input_texts,\n",
        "        max_length=128,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    batch_dict = {key: value.to(device) for key, value in batch_dict.items()}\n",
        "\n",
        "    # Get embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    # Compute scores\n",
        "    scores = (embeddings[:1] @ embeddings[1:].T) * 100  # Compute similarity scores\n",
        "    scores = scores.squeeze(0)  # Remove extra dimension for easier processing\n",
        "\n",
        "    # Dynamically determine top-k value\n",
        "    k = min(200, scores.size(0))  # Ensure k does not exceed the number of scores\n",
        "\n",
        "    # Get top-k scores and corresponding indices\n",
        "    top_scores, top_indices = torch.topk(scores, k=k)\n",
        "\n",
        "    # Map top scores to matched_items and check if real_item is in top-k\n",
        "    top_matched_items = [result['matched_items'][idx] for idx in top_indices]\n",
        "\n",
        "    # Check if real_item is in top-k\n",
        "    real_item_found = any(matched_item['item_id'] == result['real_item_id'] for matched_item in top_matched_items)\n",
        "\n",
        "    # Update count if real_item is found in top-k\n",
        "    if real_item_found:\n",
        "        real_item_in_top200_count += 1\n",
        "\n",
        "# Calculate the probability\n",
        "if total_results > 0:\n",
        "    probability = real_item_in_top200_count / total_results\n",
        "else:\n",
        "    probability = 0.0\n",
        "\n",
        "print(f\"\\nProbability of real_item appearing in top-200: {probability:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwxCz4o40RZ1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "\n",
        "# Save category mappings (required for inference)\n",
        "mappings = {\n",
        "    'category_to_idx': category_to_idx,\n",
        "    'idx_to_category': idx_to_category,\n",
        "    'num_categories': num_categories\n",
        "}\n",
        "\n",
        "with open('category_mappings.pkl', 'wb') as f:\n",
        "    pickle.dump(mappings, f)\n",
        "\n",
        "print(\"Saved category_mappings.pkl\")\n",
        "print(f\"Total categories: {num_categories}\")\n",
        "\n",
        "# NOTE: The QueryClassifier model needs to be saved BEFORE cell 20\n",
        "# because the 'model' variable gets overwritten with the E5 model.\n",
        "#\n",
        "# To save the QueryClassifier properly, add this cell between cell 18 and 20:\n",
        "#\n",
        "# # Save trained QueryClassifier\n",
        "# torch.save(model.state_dict(), 'query_classifier.pth')\n",
        "# classifier_model = model  # Keep a reference\n",
        "# print(\"Saved query_classifier.pth\")\n",
        "#\n",
        "# The E5 model doesn't need saving as it's loaded from HuggingFace\n",
        "\n",
        "print(\"\\n⚠️  WARNING: QueryClassifier model not saved!\")\n",
        "print(\"   Add the save code between cells 18-20 to preserve the trained model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaMOF5Lx0RZ2",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Loading Saved Weights for Inference\n",
        "\n",
        "To reuse the trained model in a new session, use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKKpa_H00RZ2"
      },
      "outputs": [],
      "source": [
        "# Example: How to load saved weights for inference\n",
        "import torch\n",
        "import pickle\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
        "from torch import nn\n",
        "\n",
        "# 1. Load category mappings\n",
        "with open('category_mappings.pkl', 'rb') as f:\n",
        "    mappings = pickle.load(f)\n",
        "\n",
        "category_to_idx = mappings['category_to_idx']\n",
        "idx_to_category = mappings['idx_to_category']\n",
        "num_categories = mappings['num_categories']\n",
        "\n",
        "print(f\"Loaded {num_categories} categories\")\n",
        "\n",
        "# 2. Reconstruct QueryClassifier model architecture\n",
        "class QueryClassifier(nn.Module):\n",
        "    def __init__(self, num_categories):\n",
        "        super(QueryClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-large-uncased\")\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.bert.config.hidden_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_categories)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_token = outputs.last_hidden_state[:, 0, :]\n",
        "        logits = self.classifier(cls_token)\n",
        "        return logits\n",
        "\n",
        "# 3. Load trained weights\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "classifier = QueryClassifier(num_categories).to(device)\n",
        "classifier.load_state_dict(torch.load('query_classifier.pth', map_location=device))\n",
        "classifier.eval()\n",
        "\n",
        "print(\"✓ QueryClassifier loaded successfully\")\n",
        "\n",
        "# 4. Load E5 model for semantic similarity\n",
        "e5_tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-base')\n",
        "e5_model = AutoModel.from_pretrained('intfloat/multilingual-e5-base').to(device)\n",
        "\n",
        "print(\"✓ E5 model loaded successfully\")\n",
        "print(\"\\nModels ready for inference!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM7wm1HO0RZ2"
      },
      "source": [
        "## Optimized Version - Pre-compute Embeddings\n",
        "\n",
        "The original approach recomputes embeddings for the same items repeatedly. This optimized version pre-computes all item embeddings once, reducing runtime from ~2 hours to ~5-10 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "k1VT9DAP0RZ2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-computing embeddings for 19522 unique items...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing item embeddings: 100%|██████████████████████████████████████████████████████| 153/153 [01:36<00:00,  1.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Pre-computed 19522 item embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Pre-compute embeddings for all unique items\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create a mapping of item_id to metadata\n",
        "item_id_to_metadata = {item['item_id']: item['metadata'] for item in new_list}\n",
        "unique_item_ids = list(item_id_to_metadata.keys())\n",
        "\n",
        "print(f\"Pre-computing embeddings for {len(unique_item_ids)} unique items...\")\n",
        "\n",
        "# Pre-compute embeddings in batches\n",
        "item_embeddings = {}\n",
        "batch_size = 128  # Adjust based on GPU memory\n",
        "\n",
        "for i in tqdm(range(0, len(unique_item_ids), batch_size), desc=\"Computing item embeddings\"):\n",
        "    batch_ids = unique_item_ids[i:i+batch_size]\n",
        "    batch_texts = [f\"passage: {item_id_to_metadata[item_id]}\" for item_id in batch_ids]\n",
        "\n",
        "    # Tokenize batch\n",
        "    batch_dict = tokenizer(\n",
        "        batch_texts,\n",
        "        max_length=128,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    batch_dict = {key: value.to(device) for key, value in batch_dict.items()}\n",
        "\n",
        "    # Get embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    # Store embeddings\n",
        "    for item_id, emb in zip(batch_ids, embeddings):\n",
        "        item_embeddings[item_id] = emb.cpu()  # Move to CPU to save GPU memory\n",
        "\n",
        "print(f\"✓ Pre-computed {len(item_embeddings)} item embeddings\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "r6sZLBgw0RZ2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing query batches: 100%|███████████████████████████████████████████████████████| 64/64 [1:03:27<00:00, 59.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Probability of real_item appearing in top-200: 71.26%\n",
            "Found 1443 out of 2025 items\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Compute query embeddings and evaluate (MUCH FASTER)\n",
        "real_item_in_top200_count = 0\n",
        "total_results = len(result_list)\n",
        "\n",
        "# Process queries in batches for even more speedup\n",
        "query_batch_size = 32\n",
        "\n",
        "for batch_start in tqdm(range(0, len(result_list), query_batch_size), desc=\"Processing query batches\"):\n",
        "    batch_end = min(batch_start + query_batch_size, len(result_list))\n",
        "    batch_results = result_list[batch_start:batch_end]\n",
        "\n",
        "    # Prepare batch queries\n",
        "    batch_query_texts = [f\"query: {result['query']}\" for result in batch_results]\n",
        "\n",
        "    # Tokenize query batch\n",
        "    query_batch_dict = tokenizer(\n",
        "        batch_query_texts,\n",
        "        max_length=128,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    query_batch_dict = {key: value.to(device) for key, value in query_batch_dict.items()}\n",
        "\n",
        "    # Get query embeddings\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**query_batch_dict)\n",
        "        query_embeddings = average_pool(outputs.last_hidden_state, query_batch_dict['attention_mask'])\n",
        "        query_embeddings = F.normalize(query_embeddings, p=2, dim=1)\n",
        "\n",
        "    # Process each query in the batch\n",
        "    for idx, (result, query_emb) in enumerate(zip(batch_results, query_embeddings)):\n",
        "        # Get pre-computed embeddings for matched items\n",
        "        matched_item_ids = [item['item_id'] for item in result['matched_items']]\n",
        "\n",
        "        # Stack embeddings for matched items\n",
        "        matched_embeddings = torch.stack([\n",
        "            item_embeddings[item_id].to(device) for item_id in matched_item_ids\n",
        "        ])\n",
        "\n",
        "        # Compute similarity scores\n",
        "        scores = (query_emb.unsqueeze(0) @ matched_embeddings.T) * 100\n",
        "        scores = scores.squeeze(0)\n",
        "\n",
        "        # Get top-k\n",
        "        k = min(200, scores.size(0))\n",
        "        top_scores, top_indices = torch.topk(scores, k=k)\n",
        "\n",
        "        # Check if real item is in top-k\n",
        "        top_matched_items = [result['matched_items'][idx] for idx in top_indices.cpu().numpy()]\n",
        "        real_item_found = any(item['item_id'] == result['real_item_id'] for item in top_matched_items)\n",
        "\n",
        "        if real_item_found:\n",
        "            real_item_in_top200_count += 1\n",
        "\n",
        "# Calculate probability\n",
        "probability = real_item_in_top200_count / total_results if total_results > 0 else 0.0\n",
        "print(f\"\\nProbability of real_item appearing in top-200: {probability:.2%}\")\n",
        "print(f\"Found {real_item_in_top200_count} out of {total_results} items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0EpH-z90RZ2"
      },
      "outputs": [],
      "source": [
        "# Optional: Save pre-computed embeddings for future use\n",
        "torch.save(item_embeddings, 'item_embeddings.pth')\n",
        "print(f\"✓ Saved item embeddings to item_embeddings.pth\")\n",
        "print(f\"  File contains {len(item_embeddings)} item embeddings\")\n",
        "\n",
        "# To load later:\n",
        "# item_embeddings = torch.load('item_embeddings.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wwk8CcR0RZ2"
      },
      "source": [
        "## Additional Optimization Options\n",
        "\n",
        "If you need even more speed:\n",
        "\n",
        "1. **Use FAISS for similarity search** (2-5x faster for large candidate sets)\n",
        "   - Pre-build FAISS index for all items\n",
        "   - GPU-accelerated approximate nearest neighbor search\n",
        "   \n",
        "2. **Reduce candidate pool size**\n",
        "   - Use top-1 category instead of top-2 (fewer candidates)\n",
        "   - Pre-filter items before computing similarities\n",
        "   \n",
        "3. **Mixed precision (FP16)**\n",
        "   - Use `torch.cuda.amp.autocast()` for faster inference\n",
        "   - Can be 2x faster on modern GPUs\n",
        "\n",
        "4. **Batch all queries at once** (if GPU memory allows)\n",
        "   - Process all 2,025 queries in larger batches\n",
        "   - Trade memory for speed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iysjeFPX0RZ2"
      },
      "source": [
        "## Debugging Accuracy Differences\n",
        "\n",
        "The batched version may produce slightly different results due to padding differences. Let's verify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED80iNI90RZ2"
      },
      "outputs": [],
      "source": [
        "# Compare embeddings from both methods for the first query\n",
        "test_result = result_list[0]\n",
        "test_query = f\"query: {test_result['query']}\"\n",
        "test_items = [f\"passage: {item['metadata']}\" for item in test_result['matched_items'][:5]]\n",
        "\n",
        "# Method 1: Original (tokenize together)\n",
        "input_texts_together = [test_query] + test_items\n",
        "batch_together = tokenizer(input_texts_together, max_length=128, padding=True, truncation=True, return_tensors='pt')\n",
        "print(f\"Original method - input_ids shape: {batch_together['input_ids'].shape}\")\n",
        "print(f\"Padding length: {batch_together['input_ids'].shape[1]}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**{k: v.to(device) for k, v in batch_together.items()})\n",
        "    emb_together = average_pool(outputs.last_hidden_state, batch_together['attention_mask'].to(device))\n",
        "    emb_together = F.normalize(emb_together, p=2, dim=1)\n",
        "\n",
        "# Method 2: Optimized (tokenize separately)\n",
        "batch_query = tokenizer([test_query], max_length=128, padding=True, truncation=True, return_tensors='pt')\n",
        "batch_items = tokenizer(test_items, max_length=128, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "print(f\"\\nOptimized method - query shape: {batch_query['input_ids'].shape}\")\n",
        "print(f\"Optimized method - items shape: {batch_items['input_ids'].shape}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    q_out = model(**{k: v.to(device) for k, v in batch_query.items()})\n",
        "    emb_query = average_pool(q_out.last_hidden_state, batch_query['attention_mask'].to(device))\n",
        "    emb_query = F.normalize(emb_query, p=2, dim=1)\n",
        "\n",
        "    i_out = model(**{k: v.to(device) for k, v in batch_items.items()})\n",
        "    emb_items = average_pool(i_out.last_hidden_state, batch_items['attention_mask'].to(device))\n",
        "    emb_items = F.normalize(emb_items, p=2, dim=1)\n",
        "\n",
        "# Compare embeddings\n",
        "print(f\"\\nQuery embedding difference: {torch.max(torch.abs(emb_together[0] - emb_query[0])).item():.6f}\")\n",
        "print(f\"Item embeddings max difference: {torch.max(torch.abs(emb_together[1:] - emb_items)).item():.6f}\")\n",
        "\n",
        "# Compare scores\n",
        "scores_original = (emb_together[:1] @ emb_together[1:].T) * 100\n",
        "scores_optimized = (emb_query @ emb_items.T) * 100\n",
        "print(f\"\\nScore difference: {torch.max(torch.abs(scores_original - scores_optimized)).item():.6f}\")\n",
        "print(f\"Scores are identical: {torch.allclose(scores_original, scores_optimized, atol=1e-5)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgmB8tdW0RZ2"
      },
      "source": [
        "## Fixed Version - Guaranteed Identical Results\n",
        "\n",
        "The issue is `padding=True` uses different padding lengths per batch. Using `padding=\"max_length\"` ensures identical results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0823MO8S0RZ2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-computing embeddings for 19522 unique items...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing item embeddings: 100%|██████████████████████████████████████████████████████| 153/153 [00:51<00:00,  2.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Pre-computed 19522 item embeddings with fixed padding\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Pre-compute embeddings with FIXED padding\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "item_id_to_metadata = {item['item_id']: item['metadata'] for item in new_list}\n",
        "unique_item_ids = list(item_id_to_metadata.keys())\n",
        "\n",
        "print(f\"Pre-computing embeddings for {len(unique_item_ids)} unique items...\")\n",
        "\n",
        "item_embeddings_fixed = {}\n",
        "batch_size = 128\n",
        "\n",
        "for i in tqdm(range(0, len(unique_item_ids), batch_size), desc=\"Computing item embeddings\"):\n",
        "    batch_ids = unique_item_ids[i:i+batch_size]\n",
        "    batch_texts = [f\"passage: {item_id_to_metadata[item_id]}\" for item_id in batch_ids]\n",
        "\n",
        "    # Use padding=\"max_length\" instead of padding=True\n",
        "    batch_dict = tokenizer(\n",
        "        batch_texts,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",  # FIXED: Always pad to 128\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    batch_dict = {key: value.to(device) for key, value in batch_dict.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch_dict)\n",
        "        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
        "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "    for item_id, emb in zip(batch_ids, embeddings):\n",
        "        item_embeddings_fixed[item_id] = emb.cpu()\n",
        "\n",
        "print(f\"✓ Pre-computed {len(item_embeddings_fixed)} item embeddings with fixed padding\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "olEhIv5w0RZ9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing query batches: 100%|█████████████████████████████████████████████████████████| 64/64 [04:58<00:00,  4.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "With FIXED padding:\n",
            "Probability of real_item appearing in top-200: 71.26%\n",
            "Found 1443 out of 2025 items\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Evaluate with FIXED padding (should match original exactly)\n",
        "real_item_in_top200_count = 0\n",
        "total_results = len(result_list)\n",
        "query_batch_size = 32\n",
        "\n",
        "for batch_start in tqdm(range(0, len(result_list), query_batch_size), desc=\"Processing query batches\"):\n",
        "    batch_end = min(batch_start + query_batch_size, len(result_list))\n",
        "    batch_results = result_list[batch_start:batch_end]\n",
        "\n",
        "    batch_query_texts = [f\"query: {result['query']}\" for result in batch_results]\n",
        "\n",
        "    # Use padding=\"max_length\" instead of padding=True\n",
        "    query_batch_dict = tokenizer(\n",
        "        batch_query_texts,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",  # FIXED: Always pad to 128\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    query_batch_dict = {key: value.to(device) for key, value in query_batch_dict.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**query_batch_dict)\n",
        "        query_embeddings = average_pool(outputs.last_hidden_state, query_batch_dict['attention_mask'])\n",
        "        query_embeddings = F.normalize(query_embeddings, p=2, dim=1)\n",
        "\n",
        "    for result, query_emb in zip(batch_results, query_embeddings):\n",
        "        matched_item_ids = [item['item_id'] for item in result['matched_items']]\n",
        "\n",
        "        matched_embeddings = torch.stack([\n",
        "            item_embeddings_fixed[item_id].to(device) for item_id in matched_item_ids\n",
        "        ])\n",
        "\n",
        "        scores = (query_emb.unsqueeze(0) @ matched_embeddings.T) * 100\n",
        "        scores = scores.squeeze(0)\n",
        "\n",
        "        k = min(200, scores.size(0))\n",
        "        top_scores, top_indices = torch.topk(scores, k=k)\n",
        "\n",
        "        top_matched_items = [result['matched_items'][i] for i in top_indices.cpu().numpy()]\n",
        "        real_item_found = any(item['item_id'] == result['real_item_id'] for item in top_matched_items)\n",
        "\n",
        "        if real_item_found:\n",
        "            real_item_in_top200_count += 1\n",
        "\n",
        "probability = real_item_in_top200_count / total_results if total_results > 0 else 0.0\n",
        "print(f\"\\nWith FIXED padding:\")\n",
        "print(f\"Probability of real_item appearing in top-200: {probability:.2%}\")\n",
        "print(f\"Found {real_item_in_top200_count} out of {total_results} items\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "small-small-65.45\n",
        "big-small 68.56\n",
        "small-big 66.05\n",
        "big-big 71.26"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
